---
title: "解读双编码器和交叉编码器：信息检索中的向量表示与语义匹配"
date: 2024-12-07T14:44:44Z
draft: ["false"]
tags: [
  "fetched",
  "数据派THU"
]
categories: ["Acdemic"]
---
解读双编码器和交叉编码器：信息检索中的向量表示与语义匹配 by 数据派THU
------
<div><h3 data-mpa-powered-by="yiban.io"><section data-style='margin-bottom: 0px; text-wrap: wrap; outline: 0px; font-family: system-ui, -apple-system, BlinkMacSystemFont, "Helvetica Neue", "PingFang SC", "Hiragino Sans GB", "Microsoft YaHei UI", "Microsoft YaHei", Arial, sans-serif; background-color: rgb(255, 255, 255); color: rgb(51, 51, 51); letter-spacing: normal; text-align: left; line-height: 1.5em; visibility: visible;'><img data-backh="104" data-backw="578" data-imgfileid="100164981" data-ratio="0.1800356506238859" data-src="https://mmbiz.qpic.cn/mmbiz_png/heS6wRSHVMmbq1qLbfTGuk3jmOPpGT7D5XWia0mA8twb2poibaBnypJvy5dMj7FGbQAjz6ic69NSHthvJ7jQqgz2g/640?wx_fmt=other&amp;wxfrom=5&amp;wx_lazy=1&amp;wx_co=1&amp;tp=webp" data-type="png" data-w="561" src="https://mmbiz.qpic.cn/mmbiz_png/heS6wRSHVMmbq1qLbfTGuk3jmOPpGT7D5XWia0mA8twb2poibaBnypJvy5dMj7FGbQAjz6ic69NSHthvJ7jQqgz2g/640?wx_fmt=other&amp;wxfrom=5&amp;wx_lazy=1&amp;wx_co=1&amp;tp=webp"></section><pre data-mpa-powered-by="yiban.io" data-style="margin-bottom: 0em; outline: 0px; letter-spacing: 0.544px; background-color: rgb(255, 255, 255); color: rgb(34, 34, 34); visibility: visible;"><section><section><section><section><span><span>来</span><span><span>源</span>：Deephub Imba</span></span></section></section></section></section><section powered-by="xiumi.us"><section><section data-style="margin-top: -4px; padding: 10px; outline: 0px; background-color: rgb(239, 239, 239); border-width: 0px; visibility: visible; color: rgb(196, 196, 196) !important;"><section powered-by="xiumi.us"><section><p><span>本文<strong><span><strong>约2700字</strong></span></strong>，建议阅读<strong><span><strong>5分钟</strong></span></strong></span></p><p><span>本文解读双编码器和交叉编码器。</span></p></section></section></section></section></section></pre></h3><p><br></p><section><span>在信息检索领域（即从海量数据中查找相关信息），双编码器和交叉编码器是两种至关重要的工具。它们各自拥有独特的工作机制、优势和局限性。章的第二篇，本文将深入探讨这两种核心技术。</span></section><section><span><br></span></section><h2 cid="n5" mdtype="heading"><span><strong><span>双编码器：高效的大规模检索</span></strong></span></h2><p><span><br></span></p><section><span>双编码器分别处理文档和搜索查询。可以将其类比为两个人独立工作：一人负责概括文档，另一人则专注于搜索查询，两者之间互不交流。“双”字体现了查询和文档的独立编码过程。</span></section><section><span><br></span></section><section><img data-imgfileid="100164979" data-ratio="0.8078125" data-s="300,640" data-src="https://mmbiz.qpic.cn/mmbiz_jpg/6wQyVOrkRNIiaB86icoia408Eib0zkQh2w4jxbFNdNpyBktB7QKNhul7CEAWE0u9BgrImiaLyvBLm6rteQW9d5GQb2Q/640?wx_fmt=jpeg&amp;from=appmsg&amp;wxfrom=13&amp;tp=wxpic" data-type="webp" data-w="640" src="https://mmbiz.qpic.cn/mmbiz_jpg/6wQyVOrkRNIiaB86icoia408Eib0zkQh2w4jxbFNdNpyBktB7QKNhul7CEAWE0u9BgrImiaLyvBLm6rteQW9d5GQb2Q/640?wx_fmt=jpeg&amp;from=appmsg&amp;wxfrom=13&amp;tp=wxpic"></section><section><br></section><section><span>用户查询和文档向量嵌入使用相同的嵌入模型计算，但两者完全隔离。</span></section><section><span><br></span></section><blockquote cid="n9" mdtype="blockquote"><section><span>双编码器尤其适用于需要大规模实时检索的场景，例如搜索引擎或大型知识库。</span></section></blockquote><h3 cid="n11" mdtype="heading"><span><br></span></h3><h3 cid="n11" mdtype="heading"><span><strong><span>双编码器的关键特性</span></strong></span></h3><p><span><br></span></p><section><span>独立处理</span></section><section><span><br></span></section><ul cid="n13" mdtype="list" data-mark="*"><li><section><span>为查询和文档分别生成向量表示</span></section></li><li><section><span>允许预先计算文档嵌入</span></section></li><li><section><span>可将输入查询与数百万个预编码文档快速比较</span></section></li></ul><section><span><br></span></section><section><span>与近似最近邻 (ANN) 算法的兼容性</span></section><section><span><br></span></section><ul cid="n22" mdtype="list" data-mark="*"><li><section><span>固定维度向量表示非常适合 ANN 算法</span></section></li><li><section><span>通过在向量空间中逼近最近邻，高效搜索大型数据集</span></section></li><li><section><span>适用于处理海量数据的系统的快速检索</span></section></li></ul><section><span><br></span></section><section><span>对比学习</span></section><section><span><br></span></section><ul cid="n31" mdtype="list" data-mark="*"><li><section><span>通常使用对比学习技术进行训练</span></section></li><li><section><span>学习区分相似和不相似（正负样本）的查询-文档对</span></section></li><li><section><span>创建一个语义相似的项彼此更接近的向量空间</span></section></li></ul><h3 cid="n39" mdtype="heading"><span><br></span></h3><h3 cid="n39" mdtype="heading"><span>优势</span></h3><p><span><br></span></p><ul cid="n40" mdtype="list" data-mark="*"><li><section><span>高效搜索大型数据集</span></section></li><li><section><span>适用于实时应用</span></section></li><li><section><span>适用于初始的广度优先搜索</span></section></li></ul><h3 cid="n48" mdtype="heading"><span><br></span></h3><h3 cid="n48" mdtype="heading"><span>局限性</span></h3><p><span><br></span></p><ul cid="n49" mdtype="list" data-mark="*"><li><section><span>可能忽略查询和文档之间细微的语义关系</span></section></li><li><section><span>与交叉编码器相比，处理复杂查询的准确性较低</span></section></li></ul><h2 cid="n55" mdtype="heading"><span><br></span></h2><h2 cid="n55" mdtype="heading"><span><strong><span>交叉编码器：精准的相关性评估</span></strong></span></h2><p><span><br></span></p><section><span>交叉编码器将搜索查询和每个文档一同进行比对，如同一个人仔细地逐一比较两份文本。这种方法通常能更准确地评估相关性，使交叉编码器在需要高精度语义匹配的任务中极具价值。</span></section><section><span><br></span></section><section><img data-imgfileid="100164978" data-ratio="0.6625" data-s="300,640" data-src="https://mmbiz.qpic.cn/mmbiz_jpg/6wQyVOrkRNIiaB86icoia408Eib0zkQh2w4jl0pLHYnxotX8KzXBQvxNqjL4M32JAmvTFPmhCd2M5Gd8icAgxQzbpsw/640?wx_fmt=jpeg&amp;from=appmsg&amp;tp=wxpic&amp;wxfrom=5&amp;wx_lazy=1&amp;wx_co=1" data-type="webp" data-w="640" src="https://mmbiz.qpic.cn/mmbiz_jpg/6wQyVOrkRNIiaB86icoia408Eib0zkQh2w4jl0pLHYnxotX8KzXBQvxNqjL4M32JAmvTFPmhCd2M5Gd8icAgxQzbpsw/640?wx_fmt=jpeg&amp;from=appmsg&amp;tp=wxpic&amp;wxfrom=5&amp;wx_lazy=1&amp;wx_co=1"></section><section><br></section><section><span>交叉编码器将两个文本片段（例如，用户查询和文档）同时作为输入。它不分别生成向量表示，而是输出 0 到 1 之间的值，表示输入对的相似度。</span></section><section><span><br></span></section><blockquote cid="n59" mdtype="blockquote"><section><span>交叉编码器在高精度至关重要的任务中尤其重要，例如在最终文档重排序阶段，或在语义匹配的准确性至关重要时。</span></section></blockquote><h3 cid="n61" mdtype="heading"><span><br></span></h3><h3 cid="n61" mdtype="heading"><span><strong><span>交叉编码器的关键方面</span></strong></span></h3><p><span><br></span></p><section><span>查询-文档对的联合处理</span></section><section><span><br></span></section><ul cid="n63" mdtype="list" data-mark="*"><li><section><span>将查询和文档作为单个输入一同处理</span></section></li><li><section><span>直接评估查询和文档之间的关系</span></section></li><li><section><span>实现更细致的语义匹配</span></section></li></ul><section><span><br></span></section><section><span>更准确地捕捉复杂关系</span></section><section><span><br></span></section><ul cid="n72" mdtype="list" data-mark="*"><li><section><span>擅长捕捉细微和复杂的语义关系</span></section></li><li><section><span>在法律或医学文档检索等领域具有重要价值</span></section></li></ul><section><span><br></span></section><section><span>高效的文档重排序</span></section><section><span><br></span></section><ul cid="n79" mdtype="list" data-mark="*"><li><section><span>通常用于检索的重排序阶段</span></section></li><li><section><span>优化双编码器检索到的初始文档集</span></section></li><li><section><span>确保语义最相关的文档排名最高</span></section></li></ul><h3 cid="n87" mdtype="heading"><span><br></span></h3><h3 cid="n87" mdtype="heading"><span>优势</span></h3><p><span><br></span></p><ul cid="n88" mdtype="list" data-mark="*"><li><section><span>更准确地评估相关性</span></section></li><li><section><span>更擅长捕捉复杂关系</span></section></li><li><section><span>适用于需要高精度的任务</span></section></li></ul><h3 cid="n96" mdtype="heading"><span><br></span></h3><h3 cid="n96" mdtype="heading"><span>局限性</span></h3><p><span><br></span></p><ul cid="n97" mdtype="list" data-mark="*"><li><section><span>对于大规模搜索，计算成本较高</span></section></li><li><section><span>不适用于海量文档集合的初始检索</span></section></li></ul><h2 cid="n103" mdtype="heading"><span><br></span></h2><h2 cid="n103" mdtype="heading"><span><strong><span>如何选择</span></strong></span></h2><p><span><br></span></p><section><span>双编码器：</span></section><section><span><br></span></section><ul cid="n105" mdtype="list" data-mark="*"><li><section><span>搜索海量文档集合</span></section></li><li><section><span>速度至关重要，例如实时网络搜索</span></section></li><li><section><span>执行初始的广度优先搜索</span></section></li></ul><section><span><br></span></section><section><span>交叉编码器：</span></section><section><span><br></span></section><ul cid="n114" mdtype="list" data-mark="*"><li><section><span>优化较小的搜索结果集</span></section></li><li><section><span>准确性比速度更重要</span></section></li><li><section><span>处理复杂查询或专业领域（例如，法律或医学搜索）</span></section></li></ul><h2 cid="n122" mdtype="heading"><span><br></span></h2><h2 cid="n122" mdtype="heading"><span><strong><span>使用的代码示例</span></strong></span></h2><p><span><br></span></p><section><span>假设有四个句子 A、B、C 和 D，需要比较所有可能的配对：</span></section><section><span><br></span></section><ul cid="n124" mdtype="list" data-mark="*"><li><section><span>双编码器需要分别编码每个句子，共需编码四次。</span></section></li><li><section><span>交叉编码器需要编码所有可能的配对，共需编码六次（AB、AC、AD、BC、BD、CD）。</span></section></li></ul><section><span><br></span></section><section><span>假设有 100,000 个句子，需要比较所有可能的配对：</span></section><section><span><br></span></section><ul cid="n131" mdtype="list" data-mark="*"><li><section><span>双编码器将编码 100,000 个句子。</span></section></li><li><section><span>交叉编码器将编码 4,999,950,000 对（根据组合公式：n! / (r!(n-r)!)，其中 n=100,000 且 r=2）。因此，交叉编码器的扩展性较差，在大规模数据集上计算成本过高。</span></section></li></ul><section><span><br></span></section><section><span>使用交叉编码器进行语义相似度检测的实际应用：尽管双编码器也可以完成此任务，但交叉编码器在牺牲一定处理速度的情况下能提供更高的准确性。</span></section><section><span><br></span></section><section><span>以下演示将使用微软的预训练模型 MS MARCO，通过两个句子对进行说明。模型输出一个分数，分数越高表示句子之间的语义相似度越高。</span></section><section><span><br></span></section><pre spellcheck="false" cid="n140" mdtype="fences"><section><ul><li><li><li><li><li><li><li><li><li><li><li><li><li><li><li><li><li><li><li></ul><pre data-lang="python"><code><span> <span># 安装 sentence_transformers 库</span></span></code><code><span> <span># pip install sentence_transformers</span></span></code><code><span> </span></code><code><span> <span>from</span> sentence_transformers <span>import</span> CrossEncoder</span></code><code><span> </span></code><code><span> <span># 初始化交叉编码器模型</span></span></code><code><span> model = CrossEncoder(<span>'cross-encoder/ms-marco-TinyBERT-L-2-v2'</span>, max_length=<span>512</span>)</span></code><code><span> </span></code><code><span> <span># 定义要比较的句子对</span></span></code><code><span> sentence_pairs = [</span></code><code><span>    (<span>'How many people live in Berlin?'</span>, <span>'Berlin had a population of 3,520,031 registered inhabitants in an area of 891.82 square kilometers.'</span>),</span></code><code><span>    (<span>'How many people live in Berlin?'</span>, <span>'Berlin is well known for its museums.'</span>)</span></code><code><span> ]</span></code><code><span> scores = model.predict(sentence_pairs)</span></code><code><span> print(scores)</span></code><code><span> </span></code><code><span> <span># 输出: array([ 7.152365 , -6.2870445], dtype=float32)</span></span></code><code><span> </span></code><code><span> <span># 结果表明，第一对句子的语义相似度远高于第二对。</span></span></code></pre></section></pre><section><span><br></span></section><section><span>下面的代码片段演示了如何使用双编码器进行语义相似性搜索。模型将查询和语料库编码成嵌入向量，然后执行相似性搜索以找到最相关的段落。结果显示前 k 个匹配项（此处 k=25），每个匹配项包含语料库 ID 和相似度分数：</span></section><section><span><br></span></section><pre spellcheck="false" cid="n142" mdtype="fences"><section><ul><li><li><li><li><li><li><li><li><li><li><li><li><li><li><li><li><li><li><li><li><li><li><li><li><li><li><li></ul><pre data-lang="python"><code><span> <span>from</span> sentence_transformers <span>import</span> SentenceTransformer, util</span></code><code><span> </span></code><code><span> <span># 初始化双编码器模型</span></span></code><code><span> <span># 使用 'multi-qa-MiniLM-L6-cos-v1'，一个用于将问题和段落编码到共享嵌入空间的紧凑模型</span></span></code><code><span> bi_encoder = SentenceTransformer(<span>'multi-qa-MiniLM-L6-cos-v1'</span>)</span></code><code><span> bi_encoder.max_seq_length = <span>256</span></span></code><code><span> </span></code><code><span> <span># 将所有文本块编码为嵌入</span></span></code><code><span> corpus_embeddings = bi_encoder.encode(chunks, convert_to_tensor=<span>True</span>, show_progress_bar=<span>True</span>)</span></code><code><span> </span></code><code><span> <span># 定义查询并搜索相关段落</span></span></code><code><span> query = <span>"what is rlhf?"</span></span></code><code><span> </span></code><code><span> <span># 编码查询并计算与所有段落的相似度</span></span></code><code><span> query_embedding = bi_encoder.encode(query, convert_to_tensor=<span>True</span>).cuda()</span></code><code><span> </span></code><code><span> <span># 检索前 25 个最相似的段落</span></span></code><code><span> top_k = <span>25</span></span></code><code><span> hits = util.semantic_search(query_embedding, corpus_embeddings, top_k=top_k)[<span>0</span>]</span></code><code><span> </span></code><code><span> print(hits)</span></code><code><span> </span></code><code><span> <span># 输出:  </span></span></code><code><span> <span># [{'corpus_id': 14679, 'score': 0.6097552180290222},</span></span></code><code><span> <span># {'corpus_id': 17387, 'score': 0.5659530162811279},</span></span></code><code><span> <span># {'corpus_id': 39564, 'score': 0.5590510368347168},</span></span></code><code><span> <span># ...]</span></span></code></pre></section></pre><section><span><br></span></section><section><span>使用高召回率但低精度的双编码器获取最相似的文本块后，可以通过第二阶段使用交叉编码器模型对结果进行重排序，利用其更高的准确性来优化结果。</span></section><section><span><br></span></section><section><span>以下是两阶段方法的实现：</span></section><section><span><br></span></section><pre spellcheck="false" cid="n145" mdtype="fences"><section><ul><li><li><li><li><li><li><li><li><li><li><li><li><li><li><li><li><li><li></ul><pre data-lang="python"><code><span> <span>from</span> sentence_transformers <span>import</span> CrossEncoder</span></code><code><span> </span></code><code><span> cross_encoder = CrossEncoder(<span>'cross-encoder/ms-marco-MiniLM-L-6-v2'</span>)</span></code><code><span> </span></code><code><span> <span># 通过将查询与每个检索到的块配对来准备交叉编码器的输入</span></span></code><code><span> cross_inp = [[query, chunks[hit[<span>'corpus_id'</span>]]] <span>for</span> hit <span>in</span> hits]</span></code><code><span> </span></code><code><span> cross_scores = cross_encoder.predict(cross_inp)</span></code><code><span> </span></code><code><span> print(cross_scores)</span></code><code><span> </span></code><code><span> <span># 输出是一个包含交叉编码器分数的数组，分数越高表示查询和文本块之间语义相似度越高。</span></span></code><code><span> <span># array([ 1.2227577 , 5.048051 , 1.2897239 , 2.205767 , 4.4136825 ,</span></span></code><code><span> <span>#       1.2272772 , 2.5638275 , 0.81847703, 2.35553   , 5.590804 ,</span></span></code><code><span> <span>#       1.3877895 , 2.9497519 , 1.6762824 , 0.7211323 , 0.16303705,</span></span></code><code><span> <span>#       1.3640019 , 2.3106787 , 1.5849439 , 2.9696884 , -1.1079378 ,</span></span></code><code><span> <span>#       0.7681126 , 1.5945492 , 2.2869687 , 3.5448399 , 2.056368 ],</span></span></code><code><span> <span>#     dtype=float32)</span></span></code></pre></section></pre><section><span><br></span></section><section><span>代码使用交叉编码器模型对双编码器识别的查询-文本块对重新评分。交叉编码器提供更准确的相似度分数，从而实现更精细的排序。这种两阶段方法结合了双编码器在初始检索阶段的高效性和交叉编码器在最终排序阶段的高精度，为语义搜索任务提供了一种均衡的解决方案。</span></section><section><span><br></span></section><h2 cid="n148" mdtype="heading"><span><strong><span>总结</span></strong></span></h2><p><span><br></span></p><section><span>双编码器和交叉编码器在现代信息检索中都扮演着至关重要的角色。双编码器提供速度和效率，是进行大规模初始搜索的理想选择。交叉编码器提供精度和深度，非常适合优化结果和处理复杂查询。理解它们的优势和局限性有助于构建能够同时处理广泛和细致信息需求的高效搜索系统。</span></section><section><span></span><br></section><section data-role="outer" label="edit by 135editor"><section data-role="outer" label="edit by 135editor"><section data-role="outer" label="edit by 135editor"><section data-role="outer" label="edit by 135editor"><section data-role="outer" label="edit by 135editor"><section><span>编辑：王菁</span></section><section><span><span><br></span></span></section><section><br></section><section data-role="outer" label="edit by 135editor"><section data-role="outer" label="edit by 135editor"><section data-tools="135编辑器" data-id="132519" data-style="outline: 0px; letter-spacing: 0.544px; background-color: rgb(255, 255, 255); font-family: system-ui, -apple-system, BlinkMacSystemFont, Arial, sans-serif; visibility: visible;"><section><section><section><br></section></section></section></section><section data-style="outline: 0px; letter-spacing: 0.544px; background-color: rgb(255, 255, 255); font-size: 16px; font-family: system-ui, -apple-system, BlinkMacSystemFont, Arial, sans-serif; visibility: visible;"><section><section><section data-style="outline: 0px; display: inline-block; width: 677px; vertical-align: top; align-self: flex-start; flex: 0 1 auto; background-color: rgb(234, 234, 234); visibility: visible;"><svg viewbox="0 0 1 1"></svg></section></section></section><section><section><section data-style="outline: 0px; display: inline-block; vertical-align: top; width: auto; align-self: stretch; flex: 0 0 0%; height: auto; border-width: 0px; background-color: rgb(166, 91, 203); line-height: 1; visibility: visible;"><section><section><svg viewbox="0 0 1 1"></svg></section></section></section><section data-style="padding-right: 12px; padding-left: 12px; outline: 0px; display: inline-block; vertical-align: top; width: auto; align-self: stretch; flex: 0 0 auto; background-color: rgb(166, 91, 203); min-width: 10%; height: auto; visibility: visible;"><section><section><p><strong>关于我们</strong></p></section></section></section><section data-style="outline: 0px; display: inline-block; vertical-align: top; width: auto; align-self: stretch; flex: 0 0 0%; height: auto; border-width: 0px; background-color: rgb(166, 91, 203); line-height: 1; visibility: visible;"><section><section><section><svg viewbox="0 0 1 1"></svg></section></section></section></section></section></section><section><section><section data-style="padding: 32px 20px 20px; outline: 0px; width: 677px; vertical-align: top; align-self: flex-start; flex: 0 0 auto; display: inline-block; border-style: solid; border-width: 1px; border-color: rgb(178, 162, 199); visibility: visible;"><section><section><p><span>数据派THU作为数据科学类公众号，背靠清华大学大数据研究中心，分享前沿数据科学与大数据技术创新研究动态、持续传播数据科学知识，努力建设数据人才聚集平台、打造中国大数据最强集团军。</span></p><p><br></p><section><mp-common-profile data-pluginname="mpprofile" data-id="MzI1MjQ2OTQ3Ng==" data-headimg="http://mmbiz.qpic.cn/mmbiz_png/heS6wRSHVMkUuToOTWS65qdgf9RhVicljUfXcOu2ick7IibmKfsdhahcjYWHicxfwUvumZEicp9EBOplvbmhiaSwIamg/300?wx_fmt=png&amp;wxfrom=19" data-nickname="数据派THU" data-alias="DatapiTHU" data-signature="清华大数据研究中心官方平台，发布团队科研、教学等最新动态及大数据领域的相关信息~" data-from="2" data-is_biz_ban="0" data-origin_num="885" data-isban="0" data-biz_account_status="0" data-index="0"></mp-common-profile></section><section><br></section><p><strong><img data-imgfileid="100164982" data-ratio="0.5222222222222223" data-src="https://mmbiz.qpic.cn/mmbiz_png/heS6wRSHVMl9XjaZU7CpIkx0kf38xWc7KHZ5EMoTiaWXGbLUq5TTibJtBaa9I5wx1t3ASgD7sCEldTWET95jmYhA/640?wx_fmt=other&amp;wxfrom=5&amp;wx_lazy=1&amp;wx_co=1&amp;tp=webp" data-type="png" data-w="1080" src="https://mmbiz.qpic.cn/mmbiz_png/heS6wRSHVMl9XjaZU7CpIkx0kf38xWc7KHZ5EMoTiaWXGbLUq5TTibJtBaa9I5wx1t3ASgD7sCEldTWET95jmYhA/640?wx_fmt=other&amp;wxfrom=5&amp;wx_lazy=1&amp;wx_co=1&amp;tp=webp"></strong></p><p><strong></strong></p><p><strong>新浪微博：@数据派THU</strong></p><p><strong>微信视频号：<strong>数据派THU</strong></strong></p><p><strong>今日头条：<strong><strong>数据派THU</strong></strong></strong></p></section></section></section></section></section></section></section></section></section></section></section></section></section><p><mp-style-type data-value="10000"></mp-style-type></p></div>  
<hr>
<a href="https://mp.weixin.qq.com/s/eKxYz4RP-3QCINHJSGX2vA",target="_blank" rel="noopener noreferrer">原文链接</a>
