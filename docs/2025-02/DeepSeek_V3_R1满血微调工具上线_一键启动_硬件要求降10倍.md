---
title: "DeepSeek V3+R1满血微调工具上线！一键启动，硬件要求降10倍"
date: 2025-02-19T08:03:39Z
draft: ["false"]
tags: [
  "fetched",
  "机器之心"
]
categories: ["Acdemic"]
---
DeepSeek V3+R1满血微调工具上线！一键启动，硬件要求降10倍 by 机器之心
------
<div><section data-mpa-powered-by="yiban.io" data-style='-webkit-tap-highlight-color: transparent; margin-bottom: 0px; outline: 0px; text-shadow: transparent 0px 0px 0px, rgba(0, 0, 0, 0.4) 0px 0px 0px; background-color: rgb(255, 255, 255); letter-spacing: 0.544px; text-wrap: wrap; caret-color: rgb(34, 34, 34); font-family: "Helvetica Neue", Helvetica, "Hiragino Sans GB", "Microsoft YaHei", Arial, sans-serif; visibility: visible; line-height: 27.2px; color: rgb(163, 163, 163) !important;' mp-original-font-size="17" mp-original-line-height="27.200000762939453"><section mp-original-font-size="17" mp-original-line-height="27.200000762939453" data-style="-webkit-tap-highlight-color: transparent; outline: 0px; text-shadow: transparent 0px 0px 0px, rgba(0, 0, 0, 0.4) 0px 0px 0px; visibility: visible; line-height: 27.2px;"><section mp-original-font-size="17" mp-original-line-height="27.200000762939453" data-style="-webkit-tap-highlight-color: transparent; outline: 0px; text-shadow: transparent 0px 0px 0px, rgba(0, 0, 0, 0.4) 0px 0px 0px; visibility: visible; line-height: 27.2px;"><section data-id="85660" data-custom="rgb(117, 117, 118)" data-color="rgb(117, 117, 118)" mp-original-font-size="17" mp-original-line-height="27.200000762939453" data-style="-webkit-tap-highlight-color: transparent; outline: 0px; text-shadow: transparent 0px 0px 0px, rgba(0, 0, 0, 0.4) 0px 0px 0px; border-width: 0px; border-style: initial; border-color: currentcolor; visibility: visible; line-height: 27.2px;"><section data-style="-webkit-tap-highlight-color: transparent; margin-top: 2em; padding-top: 0.5em; padding-bottom: 0.5em; outline: 0px; text-shadow: transparent 0px 0px 0px, rgba(0, 0, 0, 0.4) 0px 0px 0px; border-top: 1px solid rgb(204, 204, 204); border-bottom: 1px solid rgb(204, 204, 204); border-right-style: none; border-left-style: none; text-decoration: inherit; visibility: visible; line-height: 27.2px;" mp-original-font-size="17" mp-original-line-height="27.200000762939453"><section><span mp-original-font-size="15" mp-original-line-height="29.75">机器之心发布</span></section><section><span><strong>机器之心编辑部</strong></span></section></section></section></section></section></section><p><span></span></p><p><span>DeepSeek V3/ R1 火爆全网，基于原始模型的解决方案和 API 服务已随处可见，陷入低价和免费内卷。</span></p><p><span><br></span></p><p><span>如何站在巨人肩膀上，通过后训练（post-training）结合专业领域数据，低成本打造高质量私有模型，提升业务竞争力与价值？</span></p><p><span><br></span></p><p><span>已收获近 <strong><span>4 万 GitHub Star</span></strong> 的 Colossal-AI，发布<strong><span>开源大模型后训练工具箱</span></strong>，包含：</span></p><p><span><br></span></p><ul><li><p><span>DeepSeek V3/ R1 满血 671B LoRA 低成本 SFT 微调；</span></p></li><li><p><span>完整的强化学习工具链 PPO，GRPO，DPO，SimPO 等；</span></p></li><li><p><span>无缝适配 DeepSeek 系列蒸馏模型在内的 HuggingFace 开源模型；</span></p></li><li><p><span>兼容支持英伟达 GPU、华为昇腾 NPU 等多种硬件；</span></p></li><li><p><span>支持混合精度训练，gradient checkpoint 等训练加速降低成本；</span></p></li><li><p><span>灵活的训练配置接口，支持自定义奖励函数、损失函数等；</span></p></li><li><p><span>提供灵活的并行策略配置接口，包括数据并行、模型并行、专家并行、ZeRO 和 Offload 等，以适应不同硬件规模。</span></p></li></ul><p><span><br></span></p><p><span>开源地址：https://github.com/hpcaitech/ColossalAI</span></p><p><span><br></span></p><p><span><strong>低成本监督微调满血版 DeepSeek V3/R1 671B</strong></span></p><p><span><br></span></p><p><span>DeepSeek V3/R1 满血版参数高达 6710 亿，如何低成本进行低成本微调呢？仅需以下几个步骤，即可快速完成。</span></p><p><span><br></span></p><p><strong><span>数据集准备</span></strong></p><p><span><br></span></p><p><span>该脚本接收 JSONL 格式的文件作为输入数据集，例如 </span><span>https://github.com/hpcaitech/ColossalAI/blob/main/applications/ColossalChat/examples/training_scripts/lora_sft_data.jsonl</span><span>。数据集的每一行应为一个聊天对话列表。例如：</span></p><section><br></section><blockquote><section>[{"role": "user", "content": "你好，最近怎么样？"}, {"role": "assistant", "content": "我很好。今天有什么可以帮你的吗？"}]</section></blockquote><section><br></section><blockquote><section>[{"role": "user", "content": "火烧赤壁 曹操为何不拨打 119 求救？"}, {"role": "assistant", "content": "因为在三国时期，还没有电话和现代的消防系统，所以曹操无法拨打 119 求救。"}]</section></blockquote><section><br></section><section><span>该数据格式，兼容 Huggingface chat template，支持自定义 system prompt，因此可灵活按需配置。</span></section><p><span><br></span></p><p><strong><span>模型权重准备</span></strong></p><p><span><br></span></p><p><span>为保证更好的微调效果，使用 BF16 权重进行微调。</span></p><p><span><br></span></p><p><span>如果已下载了 FP8 的 DeepSeek V3/R1 权重，可以使用 DeepSeek 官方脚本 </span><span>https://github.com/deepseek-ai/DeepSeek-V3/blob/main/inference/fp8_cast_bf16.py</span><span> 通过 GPU 将权重转换为 BF16。</span></p><p><span><br></span></p><p><span>对于使用国产华为昇腾算力，可以下载 </span><span>https://gitee.com/ascend/ModelZoo-PyTorch/blob/master/MindIE/LLM/DeepSeek/DeepSeek-V2/NPU_inference/fp8_cast_bf16.py</span><span> 脚本转换权重。</span></p><p><span><br></span></p><p><strong><span>使用方法</span></strong></p><p><span><br></span></p><p><span>在准备好数据集和模型权重后，可使用 Colossal-AI 提供的一键启动脚本 </span><span>https://github.com/hpcaitech/ColossalAI/blob/main/applications/ColossalChat/examples/training_scripts/lora_finetune.py</span></p><p><span><br></span></p><p><span>该脚本与常见 SFT 脚本类似，且完全兼容 HuggingFace PEFT，启动命令：</span></p><p><br></p><blockquote><p>colossalai run --hostfile path-to-host-file --nprocpernode 8 lorafinetune.py --pretrained path-to-DeepSeek-R1-bf16 --dataset path-to-dataset.jsonl --plugin moe --lr 2e-5 --maxlength 256 -g --ep 8 --pp 3 --batchsize 24 --lorarank 8 --loraalpha 16 --numepochs 2 --warmupsteps 8 --tensorboarddir logs --save_dir DeepSeek-R1-bf16-lora</p></blockquote><p><br></p><p><span>有关每个参数的更多详细信息，可以运行 </span><span>python lora_finetune.py --help</span><span> 查看。该脚本可通过 tensorboard 记录学习率、loss、grad norm 信息，方便对训练进行监控。</span></p><p><span><br></span></p><p><strong><span>使用 LoRA 优化硬件资源消耗</span></strong></p><p><span><br></span></p><p><span>通过使用 LoRA 等优化，示例命令已将 SFT DeepSeek V3/R1 671B <strong><span>最低硬件要求降低近 10 倍</span></strong>，可使用 32 个 Ascend 910B NPU 64GB（使用 </span><span>ep=8,pp=4</span><span>）或 24 个 H100/H800 GPU（使用 </span><span>ep=8,pp=3</span><span>）。如果你通过 </span><span>--zero_cpu_offload</span><span> 启用 CPU offload，硬件要求可以进一步降低，但会损失一定的训练速度。</span></p><p><span><br></span></p><p><span>如下图验证，在 SFT DeepSeek V3/R1 671B 时，Loss 可以顺利降低：</span></p><p><span> </span></p><section><img data-imgfileid="503471920" data-ratio="1.0310391363022942" data-s="300,640" data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibLWhZUQVoNkJNzH80SsBdW9OxUXic1nIOEd3NrlUYxNGqpZUsfHkmt7IR7jOOUHejNvSwneyV6wbA/640?wx_fmt=png&amp;from=appmsg" data-type="png" data-w="741" src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibLWhZUQVoNkJNzH80SsBdW9OxUXic1nIOEd3NrlUYxNGqpZUsfHkmt7IR7jOOUHejNvSwneyV6wbA/640?wx_fmt=png&amp;from=appmsg"></section><p><br></p><p><span>对于资金充裕的开发团队，也可以使用上述脚本，<strong><span>将并行度高效扩展至数百及数千卡</span></strong>，快速完成 DeepSeek V3/R1 671B 全参微调或并行加速。</span></p><p><span><br></span></p><p><span>对于预算有限，又想借助强化学习构建自己的类 DeepSeek R1 模型， Colossal-AI 也提供了解决方案，并利用小模型对算法进行了验证。</span></p><p><span><br></span></p><p><span><strong>通过强化学习微调蒸馏版 DeepSeek</strong></span></p><p><span><br></span></p><p><span>Colossal-AI 团队验证并实现了 DeepSeek 论文中的 <strong><span>GRPO 算法及 verifiable reward</span></strong>，使用 Qwen2.5-3B-Base 模型进行了实验。其中，奖励的设计如下：</span></p><p><span><br></span></p><p><span>1.	奖励 = 0，如果格式是正确的；</span></p><p><span>2.	奖励 = 1， 如果格式是正确的但是结果是错误的；</span></p><p><span>3.	奖励 = 10，如果格式与结果都是正确的。</span></p><p><span><br></span></p><p><span>Colossal-AI 团队以 Qwen2.5-3B-Base 模型为例，提供了用于验证 GRPO 的对话模板及设定（</span><span>https://github.com/hpcaitech/ColossalAI/blob/main/applications/ColossalChat/conversation_template/Qwen_Qwen2.5-3B.json</span><span>），通过配置以下 bash 文件，即可一键启动：</span></p><p><span>https://github.com/hpcaitech/ColossalAI/blob/main/applications/ColossalChat/examples/training_scripts/train_grpo.sh</span></p><p><span><br></span></p><p><span>同时，在 GRPO 章节，Colossal-AI 团队还提供了验证过程中的部分发现及各种参数的详细描述，可供参考。 </span></p><p><span><br></span></p><p><span>代码中设计了可灵活配置奖励函数的模板，因此，用户可根据自己的具体情况设计自己的奖励函数体系。</span></p><p><span><br></span></p><p><span>由下图可以看到，即使是 3B 的模型，<strong><span>平均奖励与模型回复长度随着时间逐步增长</span></strong>。</span></p><p><br></p><p><img data-imgfileid="503471921" data-ratio="0.5101851851851852" data-s="300,640" data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibLWhZUQVoNkJNzH80SsBdWqjBeRTVicGuQkkXduN0B0vw6JtvIkXiaRAYfhu2e9RckXENKFLNyJoUQ/640?wx_fmt=png&amp;from=appmsg" data-type="png" data-w="1080" src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibLWhZUQVoNkJNzH80SsBdWqjBeRTVicGuQkkXduN0B0vw6JtvIkXiaRAYfhu2e9RckXENKFLNyJoUQ/640?wx_fmt=png&amp;from=appmsg"></p><p><span><br></span></p><p><span>随着训练的进行，我们可以看到一些有意思的例子。例如随着训练迭代，模型开始了<strong><span>自我纠正</span></strong>：</span></p><p><br></p><p><img data-imgfileid="503471922" data-ratio="0.6953703703703704" data-s="300,640" data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibLWhZUQVoNkJNzH80SsBdW6wwfm2QqicSKrvvDT9bfp6oaqzgY69bxTxZOAX3lbXUVRB2Few9TFPA/640?wx_fmt=png&amp;from=appmsg" data-type="png" data-w="1080" src="https://mmbiz.qpic.cn/sz_mmbiz_png/KmXPKA19gWibLWhZUQVoNkJNzH80SsBdW6wwfm2QqicSKrvvDT9bfp6oaqzgY69bxTxZOAX3lbXUVRB2Few9TFPA/640?wx_fmt=png&amp;from=appmsg"></p><p><br></p><p><span><strong>Colossal-AI：最佳后训练工具箱</strong></span></p><p><span><br></span></p><p><span>Colossal-AI 在深耕大模型预训练降本增效的基础上，致力于进一步成为开发者开箱即用的最佳后训练工具，帮助用户基于开源模型，低成本快速构建私有模型。</span></p><p><span><br></span></p><p><span>开源地址：https://github.com/hpcaitech/ColossalAI</span></p><p><br></p><p><br></p><p mp-original-font-size="17" mp-original-line-height="27.200000762939453" data-style='margin-top: 5px; outline: 0px; max-width: 100%; color: rgb(34, 34, 34); font-family: -apple-system, BlinkMacSystemFont, "Helvetica Neue", "PingFang SC", "Hiragino Sans GB", "Microsoft YaHei UI", "Microsoft YaHei", Arial, sans-serif; letter-spacing: 0.544px; white-space: normal; caret-color: rgb(34, 34, 34); background-color: rgb(255, 255, 255); text-align: center; line-height: 27.2px; margin-bottom: 0px; box-sizing: border-box !important; overflow-wrap: break-word !important;'><span mp-original-font-size="12" mp-original-line-height="19.200000762939453">© THE END </span></p><p mp-original-font-size="17" mp-original-line-height="27.200000762939453" data-style='margin-top: 5px; outline: 0px; max-width: 100%; color: rgb(34, 34, 34); font-family: -apple-system, BlinkMacSystemFont, "Helvetica Neue", "PingFang SC", "Hiragino Sans GB", "Microsoft YaHei UI", "Microsoft YaHei", Arial, sans-serif; letter-spacing: 0.544px; white-space: normal; caret-color: rgb(34, 34, 34); background-color: rgb(255, 255, 255); text-align: center; line-height: 27.2px; margin-bottom: 0px; box-sizing: border-box !important; overflow-wrap: break-word !important;'><span mp-original-font-size="12" mp-original-line-height="19.200000762939453">转载请联系本公众号获得授权</span></p><p mp-original-font-size="17" mp-original-line-height="27.200000762939453" data-style='margin-top: 5px; outline: 0px; max-width: 100%; color: rgb(34, 34, 34); font-family: -apple-system, BlinkMacSystemFont, "Helvetica Neue", "PingFang SC", "Hiragino Sans GB", "Microsoft YaHei UI", "Microsoft YaHei", Arial, sans-serif; letter-spacing: 0.544px; white-space: normal; caret-color: rgb(34, 34, 34); background-color: rgb(255, 255, 255); text-align: center; line-height: 27.2px; margin-bottom: 0px; box-sizing: border-box !important; overflow-wrap: break-word !important;'><span mp-original-font-size="12" mp-original-line-height="19.200000762939453">投稿或寻求报道：liyazhou@jiqizhixin.com</span></p><p><mp-style-type data-value="10000"></mp-style-type></p></div>  
<hr>
<a href="https://mp.weixin.qq.com/s/ywJAbcjXPef1RazHj1HIjg",target="_blank" rel="noopener noreferrer">原文链接</a>
