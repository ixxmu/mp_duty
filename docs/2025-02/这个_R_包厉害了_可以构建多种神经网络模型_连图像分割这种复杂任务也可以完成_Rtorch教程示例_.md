---
title: "这个 R 包厉害了！可以构建多种神经网络模型，连图像分割这种复杂任务也可以完成（Rtorch教程示例）"
date: 2025-02-11T15:19:20Z
draft: ["false"]
tags: [
  "fetched",
  "生信碱移"
]
categories: ["Acdemic"]
---
这个 R 包厉害了！可以构建多种神经网络模型，连图像分割这种复杂任务也可以完成（Rtorch教程示例） by 生信碱移
------
<div><section data-tool="markdown编辑器" data-website="https://markdown.com.cn/editor"><section powered-by="xiumi.us"><section><section powered-by="xiumi.us"><section><section><section powered-by="xiumi.us"><section><section powered-by="xiumi.us"><section><img data-imgfileid="100011914" data-ratio="1.0324675324675325" data-type="gif" data-w="154" data-src="https://mmbiz.qpic.cn/mmbiz_gif/lN9Tp5oiaqHFn9Rg6MwMU3ukMR9ROPh7bf7QWHEMwhUBUwSUKFsV8oK9noHic3jLaeJVQewHJcLq1cTXVAat35Tw/640?wx_fmt=gif&amp;wxfrom=5&amp;wx_lazy=1" src="https://mmbiz.qpic.cn/mmbiz_gif/lN9Tp5oiaqHFn9Rg6MwMU3ukMR9ROPh7bf7QWHEMwhUBUwSUKFsV8oK9noHic3jLaeJVQewHJcLq1cTXVAat35Tw/640?wx_fmt=gif&amp;wxfrom=5&amp;wx_lazy=1"></section></section></section></section></section><section><section powered-by="xiumi.us"><section><p>老铁快点击蓝字 <strong>关注俺</strong></p></section></section></section><section><section powered-by="xiumi.us"><section><section powered-by="xiumi.us"><section><img data-ratio="1.0324675324675325" data-type="gif" data-w="154" data-imgfileid="100011916" data-src="https://mmbiz.qpic.cn/mmbiz_gif/lN9Tp5oiaqHFn9Rg6MwMU3ukMR9ROPh7bf7QWHEMwhUBUwSUKFsV8oK9noHic3jLaeJVQewHJcLq1cTXVAat35Tw/640?wx_fmt=gif&amp;wxfrom=5&amp;wx_lazy=1" src="https://mmbiz.qpic.cn/mmbiz_gif/lN9Tp5oiaqHFn9Rg6MwMU3ukMR9ROPh7bf7QWHEMwhUBUwSUKFsV8oK9noHic3jLaeJVQewHJcLq1cTXVAat35Tw/640?wx_fmt=gif&amp;wxfrom=5&amp;wx_lazy=1"></section></section></section></section></section></section></section></section></section><section powered-by="xiumi.us"><section data-mpa-powered-by="yiban.io" data-style='white-space: normal; max-width: 100%; letter-spacing: 0.544px; text-size-adjust: auto; background-color: rgb(255, 255, 255); font-family: "Helvetica Neue", Helvetica, "Hiragino Sans GB", "Microsoft YaHei", Arial, sans-serif; box-sizing: border-box !important; overflow-wrap: break-word !important;'><section data-id="85660" data-custom="rgb(117, 117, 118)" data-color="rgb(117, 117, 118)"><section data-style="margin-top: 2em; padding-top: 0.5em; padding-bottom: 0.5em; max-width: 100%; border-style: solid none; text-decoration: inherit; border-top-color: rgb(204, 204, 204); border-bottom-color: rgb(204, 204, 204); border-top-width: 1px; border-bottom-width: 1px; box-sizing: border-box !important; overflow-wrap: break-word !important;"><p><span>生信碱移</span></p><section><strong>Rtorch</strong></section></section></section></section><blockquote data-type="2" data-url="" data-author-name="" data-content-utf8-length="68" data-source-title="" data-style='color: rgba(0, 0, 0, 0.498); white-space: normal; max-width: 100%; letter-spacing: 0.544px; font-family: -apple-system-font, system-ui, "Helvetica Neue", "PingFang SC", "Hiragino Sans GB", "Microsoft YaHei UI", "Microsoft YaHei", Arial, sans-serif; background-color: rgb(255, 255, 255); box-sizing: border-box !important; overflow-wrap: break-word !important;'><section><span>Rtorch，顾名思义，在 R 语言中调用神经网络构建框架 Pytorch</span></section></blockquote></section><p>经典的统计方法和简单的回归模型在面对复杂的非线性问题时，往往难以有效捕捉数据中的深层次特征。<strong>深度学习能够从数据中自动学习特征并进行复杂模式的建模，特别是在图像识别、自然语言处理和基因组学等领域表现卓越。</strong></p><p><strong><img alt="图片" data-imgfileid="100011917" data-ratio="0.8544474393530997" data-w="371" data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/LvUIqvYKCeUBoh9ibW32icCXgT9dc4XcOI18dKTB7enetYD1JNNdwKWh4wibMnEpghCZfOpACrSuicia0fL5WZ8AOJA/640?wx_fmt=png&amp;tp=webp&amp;wxfrom=5&amp;wx_lazy=1&amp;wx_co=1" src="https://mmbiz.qpic.cn/sz_mmbiz_png/LvUIqvYKCeUBoh9ibW32icCXgT9dc4XcOI18dKTB7enetYD1JNNdwKWh4wibMnEpghCZfOpACrSuicia0fL5WZ8AOJA/640?wx_fmt=png&amp;tp=webp&amp;wxfrom=5&amp;wx_lazy=1&amp;wx_co=1"></strong></p><p><strong><span>▲ 关于神经网络的易懂讲解，可以<a target="_blank" href="https://mp.weixin.qq.com/s?__biz=MzkyNTIzMzYyMA==&amp;mid=2247490624&amp;idx=1&amp;sn=7c446cc675aef1e8be0caf48bc49ebfd&amp;scene=21#wechat_redirect" textvalue="点击此处蓝字" linktype="text" imgurl="" imgdata="null" data-itemshowtype="0" tab="innerlink" data-linktype="2">点击此处蓝字</a>查看小编的另一篇文章。</span></strong></p><p data-tool="markdown.com.cn编辑器">尽管如此，生信用户最常使用的代码框架是 R 语言，而当前的主流神经网络框架 (如<span><strong>PyTorch</strong></span>) 大多基于 Python，这难免会存在一些学习成本。</p><p><img data-galleryid="" data-imgfileid="100011918" data-ratio="0.7046296296296296" data-s="300,640" data-type="png" data-w="1080" data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/LvUIqvYKCeU2uNq5LH4KHSk5kQD9JxTC2PnpK9MEaUvoOWERcD2CC80JKv4jWvPJBaoUVwXH7qCnXKHuA3UibhA/640?wx_fmt=png&amp;from=appmsg" src="https://mmbiz.qpic.cn/sz_mmbiz_png/LvUIqvYKCeU2uNq5LH4KHSk5kQD9JxTC2PnpK9MEaUvoOWERcD2CC80JKv4jWvPJBaoUVwXH7qCnXKHuA3UibhA/640?wx_fmt=png&amp;from=appmsg"></p><p data-tool="markdown.com.cn编辑器"><span><strong>Rtorch</strong></span> 包针对这种情况而被设计，<strong>它允许用户在 R 环境中享受PyTorch的高效梯度计算和灵活性</strong>，并处理大规模数据和进行更加个性化的模型框架设计。github链接如下：</p><ul data-tool="markdown.com.cn编辑器"><li><section>https://github.com/mlverse/torch</section></li></ul><h3 data-tool="markdown.com.cn编辑器"><span></span><span>0.推荐学习路线</span><span></span></h3><p data-tool="markdown.com.cn编辑器"><strong>① </strong><span><strong>入门教程</strong></span><strong>：理解 torch 的基本使用流程和神经网络训练</strong>：</p><ul data-tool="markdown.com.cn编辑器"><li><section>https://torch.mlverse.org/start/guess_the_correlation/</section></li></ul><p data-tool="markdown.com.cn编辑器"><strong>② </strong><span><strong>进行</strong></span><span><strong>实验和模型调整</strong></span><strong>，加深对深度学习的理解</strong>：</p><ul data-tool="markdown.com.cn编辑器"><li><p>https://torch.mlverse.org/start/what_if</p></li></ul><p data-tool="markdown.com.cn编辑器"><strong>③ </strong><span><strong>学习</strong></span><span><strong>创建自定义数据集</strong></span><strong>，掌握数据处理技巧</strong>:</p><ul data-tool="markdown.com.cn编辑器"><li><p>https://torch.mlverse.org/start/custom_dataset</p></li></ul><p data-tool="markdown.com.cn编辑器"><strong>④ </strong><span><strong>了解 torch 的</strong></span><span><strong>基础构建模块</strong></span><strong>，如张量、自动微分等</strong>:</p><ul data-tool="markdown.com.cn编辑器"><li><p>https://torch.mlverse.org/technical/</p></li></ul><p data-tool="markdown.com.cn编辑器"><strong>⑤ </strong><span><strong>实际应用案例</strong></span><strong>，Rtorch 在不同任务中的应用</strong>:</p><ul data-tool="markdown.com.cn编辑器"><li><section>https://torch.mlverse.org/use_torch</section></li></ul><h3 data-tool="markdown.com.cn编辑器"><span></span><span>1.R包安装与简要示例</span><span></span></h3><p data-tool="markdown.com.cn编辑器"><strong>通过Github或者CRAN皆可进行安装</strong>：</p><pre data-tool="markdown.com.cn编辑器"><span></span><code><span># 安装方式1</span><br>remotes::install_github(<span>"mlverse/torch"</span>)<br><br><span># 安装方式2</span><br>install.packages(<span>"torch"</span>)<br></code></pre><p data-tool="markdown.com.cn编辑器">安装详情指引 (必看)：</p><ul data-tool="markdown.com.cn编辑器"><li><p>https://torch.mlverse.org/docs/articles/installation.html</p></li></ul><p data-tool="markdown.com.cn编辑器">可以使用<code>torch_tensor</code>函数从 R 对象创建 torch 张量，并使用 as_array 将它们转换回 R 对象：</p><pre data-tool="markdown.com.cn编辑器"><span></span><code><span>library</span>(torch)<br>x &lt;- array(runif(<span>8</span>), dim = c(<span>2</span>, <span>2</span>, <span>2</span>))<br>y &lt;- torch_tensor(x, dtype = torch_float64())<br>y<br><span>#&gt; torch_tensor</span><br><span>#&gt; (1,.,.) = </span><br><span>#&gt;   0.6192  0.5800</span><br><span>#&gt;   0.2488  0.3681</span><br><span>#&gt; </span><br><span>#&gt; (2,.,.) = </span><br><span>#&gt;   0.0042  0.9206</span><br><span>#&gt;   0.4388  0.5664</span><br><span>#&gt; [ CPUDoubleType{2,2,2} ]</span><br>identical(x, as_array(y))<br><span>#&gt; [1] TRUE</span><br></code></pre><section><span><strong>简单的自动微分示例</strong></span><strong>：</strong></section><pre data-tool="markdown.com.cn编辑器"><span></span><code>x &lt;- torch_tensor(<span>1</span>, requires_grad = <span>TRUE</span>)<br>w &lt;- torch_tensor(<span>2</span>, requires_grad = <span>TRUE</span>)<br>b &lt;- torch_tensor(<span>3</span>, requires_grad = <span>TRUE</span>)<br>y &lt;- w * x + b<br>y$backward()<br>x$grad<br><span>#&gt; torch_tensor</span><br><span>#&gt;  2</span><br><span>#&gt; [ CPUFloatType{1} ]</span><br>w$grad<br><span>#&gt; torch_tensor</span><br><span>#&gt;  1</span><br><span>#&gt; [ CPUFloatType{1} ]</span><br>b$grad<br><span>#&gt; torch_tensor</span><br><span>#&gt;  1</span><br><span>#&gt; [ CPUFloatType{1} ]</span><br></code></pre><h3 data-tool="markdown.com.cn编辑器"><span></span><span>2.使用Rtorch进行脑图像分割</span><span></span></h3><p data-tool="markdown.com.cn编辑器">在医学中，我们可能想区分不同的细胞类型，或识别肿瘤。<span><strong>图像分割</strong></span><strong>是一种监督学习形式：需要图片位置的真实标签。</strong><span><strong>标签</strong></span><strong>以掩码的形式出现，即一幅与输入数据具有相同空间分辨率的图像，标识每个像素的真实类别（此处是否为肿瘤）。</strong>因此，分类损失是逐像素计算的，然后将损失相加以得出用于优化的总和。</p><p data-tool="markdown.com.cn编辑器">图像分割的常见架构是2015年发布的 <span><strong>U-Net</strong></span>。在这种架构中，存在许多变体。比如可以使用不同的层大小、激活函数、实现缩小和放大的方式等等。然而，有一个决定性的特征：U 形状，即在所有隐藏层水平交叉的连接桥。</p><p><img data-galleryid="" data-imgfileid="100011919" data-ratio="0.6768518518518518" data-s="300,640" data-type="png" data-w="1080" data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/LvUIqvYKCeU2uNq5LH4KHSk5kQD9JxTCOPMHoNCnAD6ge3QKuaYSs5GoNjXd0EbGsql0sySWs0IB86U8V3w99w/640?wx_fmt=png&amp;from=appmsg" src="https://mmbiz.qpic.cn/sz_mmbiz_png/LvUIqvYKCeU2uNq5LH4KHSk5kQD9JxTCOPMHoNCnAD6ge3QKuaYSs5GoNjXd0EbGsql0sySWs0IB86U8V3w99w/640?wx_fmt=png&amp;from=appmsg"></p><section><span><strong><span>图：Unet模型架构示意图</span></strong></span><span>。U 的左侧类似于用于图像分类的卷积架构，逐步降低空间分辨率。然而，与分类不同，分割任务的输出应该与输入具有相同的空间分辨率。因此，需要再次放大，这由 U 的右侧处理。但是，既然降低分辨率过程中已经丢失了如此多的空间信息，模型将如何获得良好的逐像素分类？这就是中间桥的作用：在每个层级，上采样层的输入是前一层输出的拼接，该输出经过了整个压缩/解压缩过程，以及来自缩小阶段的一些保留的中间表示。通过这种方式，U-Net 架构将对细节的关注与特征提取相结合。</span></section><p data-tool="markdown.com.cn编辑器">本示例演示检测脑部扫描中的异常，使用的数据集包含 MRI 图像以及手动创建的 FLAIR 异常分割掩码。<strong>即对于每位患者，多个位置都进行了切片，每位患者的切片数量不同。</strong></p><section><img data-galleryid="" data-imgfileid="100011920" data-ratio="0.6666666666666666" data-s="300,640" data-type="png" data-w="1080" data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/LvUIqvYKCeU2uNq5LH4KHSk5kQD9JxTCqJNa7eRElUgWsdhLlQymoR3IyPd1HEXaN1ug0YJ9mWia6vXhLIicgIgg/640?wx_fmt=png&amp;from=appmsg" src="https://mmbiz.qpic.cn/sz_mmbiz_png/LvUIqvYKCeU2uNq5LH4KHSk5kQD9JxTCqJNa7eRElUgWsdhLlQymoR3IyPd1HEXaN1ug0YJ9mWia6vXhLIicgIgg/640?wx_fmt=png&amp;from=appmsg"></section><section><span><strong>图：</strong></span><span><strong>不同样本的脑影像(上图)以及掩码<strong>(下图)</strong></strong></span><span><strong>。</strong>大多数切片没有显示任何病变，相应的掩码到处都是黑色，而有病变的掩码位置标记为白色，<strong>模型的任务便是预测任意输入样本的掩码（即病变位置）</strong>。</span></section><p data-tool="markdown.com.cn编辑器"><strong>① </strong><span><strong>使用pins</strong><strong>包加载数据</strong></span><strong>:</strong></p><pre data-tool="markdown.com.cn编辑器"><span></span><code><span># deep learning (incl. dependencies)</span><br><span>library</span>(torch)<br><span>library</span>(torchvision)<br><br><span># data wrangling</span><br><span>library</span>(tidyverse)<br><span>library</span>(zeallot)<br><br><span># image processing and visualization</span><br><span>library</span>(magick)<br><span>library</span>(cowplot)<br><br><span># dataset loading </span><br><span>library</span>(pins)<br><span>library</span>(zip)<br><br>torch_manual_seed(<span>777</span>)<br>set.seed(<span>777</span>)<br><br><span># use your own kaggle.json here</span><br>pins::board_register_kaggle(token = <span>"~/kaggle.json"</span>)<br><br>files &lt;- pins::pin_get(<span>"mateuszbuda/lgg-mri-segmentation"</span>, board = <span>"kaggle"</span>,  extract = <span>FALSE</span>)</code></pre><p><strong>② </strong><span><strong>创建训练与验证集</strong></span><strong>：</strong></p><pre data-tool="markdown.com.cn编辑器"><span></span><code>train_dir &lt;- <span>"data/mri_train"</span><br>valid_dir &lt;- <span>"data/mri_valid"</span><br><br><span>if</span>(dir.exists(train_dir)) unlink(train_dir, recursive = <span>TRUE</span>, force = <span>TRUE</span>)<br><span>if</span>(dir.exists(valid_dir)) unlink(valid_dir, recursive = <span>TRUE</span>, force = <span>TRUE</span>)<br><br>zip::unzip(files, exdir = <span>"data"</span>)<br><br>file.rename(<span>"data/kaggle_3m"</span>, train_dir)<br><br><span># this is a duplicate, again containing kaggle_3m (evidently a packaging error on Kaggle)</span><br><span># we just remove it</span><br>unlink(<span>"data/lgg-mri-segmentation"</span>, recursive = <span>TRUE</span>)<br><br>dir.create(valid_dir)<br><br><span># 110 名患者中，保留 30 名用于验证</span><br>valid_indices &lt;- sample(<span>1</span>:length(patients), <span>30</span>)<br><br>patients &lt;- list.dirs(train_dir, recursive = <span>FALSE</span>)<br><br><span>for</span> (i <span>in</span> valid_indices) {<br>  dir.create(file.path(valid_dir, basename(patients[i])))<br>  <span>for</span> (f <span>in</span> list.files(patients[i])) {    <br>    file.rename(file.path(train_dir, basename(patients[i]), f), file.path(valid_dir, basename(patients[i]), f))    <br>  }<br>  unlink(file.path(train_dir, basename(patients[i])), recursive = <span>TRUE</span>)<br>}<br></code></pre><section><strong>③ </strong><span><strong>创建torch数据加载器</strong></span><code>Dataset</code>：</section><pre data-tool="markdown.com.cn编辑器"><span></span><code>brainseg_dataset &lt;- dataset(<br>  name = <span>"brainseg_dataset"</span>,<br>  <br>  initialize = <span>function</span>(img_dir,<br>                        augmentation_params = <span>NULL</span>,<br>                        random_sampling = <span>FALSE</span>) {<br>    self$images &lt;- tibble(<br>      img = grep(<br>        list.files(<br>          img_dir,<br>          full.names = <span>TRUE</span>,<br>          pattern = <span>"tif"</span>,<br>          recursive = <span>TRUE</span><br>        ),<br>        pattern = <span>'mask'</span>,<br>        invert = <span>TRUE</span>,<br>        value = <span>TRUE</span><br>      ),<br>      mask = grep(<br>        list.files(<br>          img_dir,<br>          full.names = <span>TRUE</span>,<br>          pattern = <span>"tif"</span>,<br>          recursive = <span>TRUE</span><br>        ),<br>        pattern = <span>'mask'</span>,<br>        value = <span>TRUE</span><br>      )<br>    )<br>    self$slice_weights &lt;- self$calc_slice_weights(self$images$mask)<br>    self$augmentation_params &lt;- augmentation_params<br>    self$random_sampling &lt;- random_sampling<br>  },<br>  <br>  .getitem = <span>function</span>(i) {<br>    index &lt;-<br>      <span>if</span> (self$random_sampling == <span>TRUE</span>)<br>        sample(<span>1</span>:self$.length(), <span>1</span>, prob = self$slice_weights)<br>    <span>else</span><br>      i<br>    <br>    img &lt;- self$images$img[index] %&gt;%<br>      image_read() %&gt;%<br>      transform_to_tensor() <br>    mask &lt;- self$images$mask[index] %&gt;%<br>      image_read() %&gt;%<br>      transform_to_tensor() %&gt;%<br>      transform_rgb_to_grayscale() %&gt;%<br>      torch_unsqueeze(<span>1</span>)<br>    <br>    img &lt;- self$min_max_scale(img)<br>    <br>    <span>if</span> (!is.null(self$augmentation_params)) {<br>      scale_param &lt;- self$augmentation_params[<span>1</span>]<br>      c(img, mask) %&lt;-% self$resize(img, mask, scale_param)<br>      <br>      rot_param &lt;- self$augmentation_params[<span>2</span>]<br>      c(img, mask) %&lt;-% self$rotate(img, mask, rot_param)<br>      <br>      flip_param &lt;- self$augmentation_params[<span>3</span>]<br>      c(img, mask) %&lt;-% self$flip(img, mask, flip_param)<br>      <br>    }<br>    list(img = img, mask = mask)<br>  },<br>  <br>  .length = <span>function</span>() {<br>    nrow(self$images)<br>  },<br>  <br>  calc_slice_weights = <span>function</span>(masks) {<br>    weights &lt;- map_dbl(masks, <span>function</span>(m) {<br>      img &lt;-<br>        as.integer(magick::image_data(image_read(m), channels = <span>"gray"</span>))<br>      sum(img / <span>255</span>)<br>    })<br>    <br>    sum_weights &lt;- sum(weights)<br>    num_weights &lt;- length(weights)<br>    <br>    weights &lt;- weights %&gt;% map_dbl(<span>function</span>(w) {<br>      w &lt;- (w + sum_weights * <span>0.1</span> / num_weights) / (sum_weights * <span>1.1</span>)<br>    })<br>    weights<br>  },<br>  <br>  min_max_scale = <span>function</span>(x) {<br>    min = x$min()$item()<br>    max = x$max()$item()<br>    x$clamp_(min = min, max = max)<br>    x$add_(-min)$div_(max - min + <span>1e-5</span>)<br>    x<br>  },<br>  <br>  resize = <span>function</span>(img, mask, scale_param) {<br>    img_size &lt;- dim(img)[<span>2</span>]<br>    rnd_scale &lt;- runif(<span>1</span>, <span>1</span> - scale_param, <span>1</span> + scale_param)<br>    img &lt;- transform_resize(img, size = rnd_scale * img_size)<br>    mask &lt;- transform_resize(mask, size = rnd_scale * img_size)<br>    diff &lt;- dim(img)[<span>2</span>] - img_size<br>    <span>if</span> (diff &gt; <span>0</span>) {<br>      top &lt;- ceiling(diff / <span>2</span>)<br>      left &lt;- ceiling(diff / <span>2</span>)<br>      img &lt;- transform_crop(img, top, left, img_size, img_size)<br>      mask &lt;- transform_crop(mask, top, left, img_size, img_size)<br>    } <span>else</span> {<br>      img &lt;- transform_pad(img,<br>                           padding = -c(<br>                             ceiling(diff / <span>2</span>),<br>                             floor(diff / <span>2</span>),<br>                             ceiling(diff / <span>2</span>),<br>                             floor(diff / <span>2</span>)<br>                           ))<br>      mask &lt;- transform_pad(mask, padding = -c(<br>        ceiling(diff / <span>2</span>),<br>        floor(diff /<br>                <span>2</span>),<br>        ceiling(diff /<br>                  <span>2</span>),<br>        floor(diff /<br>                <span>2</span>)<br>      ))<br>    }<br>    list(img, mask)<br>  },<br>  <br>  rotate = <span>function</span>(img, mask, rot_param) {<br>    rnd_rot &lt;- runif(<span>1</span>, <span>1</span> - rot_param, <span>1</span> + rot_param)<br>    img &lt;- transform_rotate(img, angle = rnd_rot)<br>    mask &lt;- transform_rotate(mask, angle = rnd_rot)<br>    <br>    list(img, mask)<br>  },<br>  <br>  flip = <span>function</span>(img, mask, flip_param) {<br>    rnd_flip &lt;- runif(<span>1</span>)<br>    <span>if</span> (rnd_flip &gt; flip_param) {<br>      img &lt;- transform_hflip(img)<br>      mask &lt;- transform_hflip(mask)<br>    }<br>    <br>    list(img, mask)<br>  }<br>)<br><br>train_ds &lt;- brainseg_dataset(<br>  train_dir,<br>  augmentation_params = c(<span>0.05</span>, <span>15</span>, <span>0.5</span>),<br>  random_sampling = <span>TRUE</span><br>)<br><br>length(train_ds)<br><span># 2977</span><br><br>valid_ds &lt;- brainseg_dataset(<br>  valid_dir,<br>  augmentation_params = <span>NULL</span>,<br>  random_sampling = <span>FALSE</span><br>)<br><br>length(valid_ds)<br><span># 952</span><br></code></pre><p><strong>④ </strong><span><strong>可</strong></span><span><strong>视化一个样本与其掩码</strong></span><strong>（已知病变标签位置）</strong>：</p><pre data-tool="markdown.com.cn编辑器"><span></span><code>par(mfrow = c(<span>1</span>, <span>2</span>), mar = c(<span>0</span>, <span>1</span>, <span>0</span>, <span>1</span>))<br><br>img_and_mask &lt;- valid_ds[<span>27</span>]<br>img &lt;- img_and_mask[[<span>1</span>]]<br>mask &lt;- img_and_mask[[<span>2</span>]]<br><br>img$permute(c(<span>2</span>, <span>3</span>, <span>1</span>)) %&gt;% as.array() %&gt;% as.raster() %&gt;% plot()<br>mask$squeeze() %&gt;% as.array() %&gt;% as.raster() %&gt;% plot()<br></code></pre><section><img data-galleryid="" data-imgfileid="100011921" data-ratio="0.48148148148148145" data-s="300,640" data-type="png" data-w="1080" data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/LvUIqvYKCeU2uNq5LH4KHSk5kQD9JxTCwCZ9hBDrCF22o5rLMQI0hgQ7nLcU0TmWjibpwwhzouicAgg8RDwINcAg/640?wx_fmt=png&amp;from=appmsg" src="https://mmbiz.qpic.cn/sz_mmbiz_png/LvUIqvYKCeU2uNq5LH4KHSk5kQD9JxTCwCZ9hBDrCF22o5rLMQI0hgQ7nLcU0TmWjibpwwhzouicAgg8RDwINcAg/640?wx_fmt=png&amp;from=appmsg"></section><section><strong>⑤ </strong><span><strong>查看不同增强参数对验证集数据的影响</strong></span>：</section><pre data-tool="markdown.com.cn编辑器"><span></span><code>img_and_mask &lt;- valid_ds[<span>77</span>]<br>img &lt;- img_and_mask[[<span>1</span>]]<br>mask &lt;- img_and_mask[[<span>2</span>]]<br><br>imgs &lt;- map (<span>1</span>:<span>24</span>, <span>function</span>(i) {<br>  <br>  <span># scale factor; train_ds really uses 0.05</span><br>  c(img, mask) %&lt;-% valid_ds$resize(img, mask, <span>0.2</span>) <br>  c(img, mask) %&lt;-% valid_ds$flip(img, mask, <span>0.5</span>)<br>  <span># rotation angle; train_ds really uses 15</span><br>  c(img, mask) %&lt;-% valid_ds$rotate(img, mask, <span>90</span>) <br>  img %&gt;%<br>    transform_rgb_to_grayscale() %&gt;%<br>    as.array() %&gt;%<br>    as_tibble() %&gt;%<br>    rowid_to_column(var = <span>"Y"</span>) %&gt;%<br>    gather(key = <span>"X"</span>, value = <span>"value"</span>, -Y) %&gt;%<br>    mutate(X = as.numeric(gsub(<span>"V"</span>, <span>""</span>, X))) %&gt;%<br>    ggplot(aes(X, Y, fill = value)) +<br>    geom_raster() +<br>    theme_void() +<br>    theme(legend.position = <span>"none"</span>) +<br>    theme(aspect.ratio = <span>1</span>)<br>  <br>})<br><br>plot_grid(plotlist = imgs, nrow = <span>4</span>)<br></code></pre><p><img data-galleryid="" data-imgfileid="100011922" data-ratio="0.5787037037037037" data-s="300,640" data-type="png" data-w="1080" data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/LvUIqvYKCeU2uNq5LH4KHSk5kQD9JxTCINwIR9F4a4WAw7AksORH9lStyic0usTLd8lia7Qg89kfDIvNvSOa5y7g/640?wx_fmt=png&amp;from=appmsg" src="https://mmbiz.qpic.cn/sz_mmbiz_png/LvUIqvYKCeU2uNq5LH4KHSk5kQD9JxTCINwIR9F4a4WAw7AksORH9lStyic0usTLd8lia7Qg89kfDIvNvSOa5y7g/640?wx_fmt=png&amp;from=appmsg"></p><section><strong>⑥ </strong><span><strong>创建数据加载器</strong></span>，设置合适的批次，越大的迭代将会更快但是更加消耗资源：</section><pre data-tool="markdown.com.cn编辑器"><span></span><code>batch_size &lt;- <span>4</span> <span># 一次加载4个样本</span><br>train_dl &lt;- dataloader(train_ds, batch_size)<br>valid_dl &lt;- dataloader(valid_ds, batch_size)<br></code></pre><section><strong>⑦ </strong><span><strong>模型架构搭建</strong></span><strong>：</strong></section><pre data-tool="markdown.com.cn编辑器"><span></span><code>unet &lt;- nn_module(<br>  <span>"unet"</span>,<br>  <br>  initialize = <span>function</span>(channels_in = <span>3</span>,<br>                        n_classes = <span>1</span>,<br>                        depth = <span>5</span>,<br>                        n_filters = <span>6</span>) {<br>    <br>    self$down_path &lt;- nn_module_list()<br>    <br>    prev_channels &lt;- channels_in<br>    <span>for</span> (i <span>in</span> <span>1</span>:depth) {<br>      self$down_path$append(down_block(prev_channels, <span>2</span> ^ (n_filters + i - <span>1</span>)))<br>      prev_channels &lt;- <span>2</span> ^ (n_filters + i -<span>1</span>)<br>    }<br>    <br>    self$up_path &lt;- nn_module_list()<br>    <br>    <span>for</span> (i <span>in</span> ((depth - <span>1</span>):<span>1</span>)) {<br>      self$up_path$append(up_block(prev_channels, <span>2</span> ^ (n_filters + i - <span>1</span>)))<br>      prev_channels &lt;- <span>2</span> ^ (n_filters + i - <span>1</span>)<br>    }<br>    <br>    self$last = nn_conv2d(prev_channels, n_classes, kernel_size = <span>1</span>)<br>  },<br>  <br>  forward = <span>function</span>(x) {<br>    <br>    blocks &lt;- list()<br>    <br>    <span>for</span> (i <span>in</span> <span>1</span>:length(self$down_path)) {<br>      x &lt;- self$down_path[[i]](x)<br>      <span>if</span> (i != length(self$down_path)) {<br>        blocks &lt;- c(blocks, x)<br>        x &lt;- nnf_max_pool2d(x, <span>2</span>)<br>      }<br>    }<br>    <br>    <span>for</span> (i <span>in</span> <span>1</span>:length(self$up_path)) {  <br>      x &lt;- self$up_path[[i]](x, blocks[[length(blocks) - i + <span>1</span>]]$to(device = device))<br>    }<br>    <br>    torch_sigmoid(self$last(x))<br>  }<br>)<br><br>down_block &lt;- nn_module(<br>  <span>"down_block"</span>,<br>  <br>  initialize = <span>function</span>(in_size, out_size) {<br>    self$conv_block &lt;- conv_block(in_size, out_size)<br>  },<br>  <br>  forward = <span>function</span>(x) {<br>    self$conv_block(x)<br>  }<br>)<br><br>up_block &lt;- nn_module(<br>  <span>"up_block"</span>,<br>  <br>  initialize = <span>function</span>(in_size, out_size) {<br>    <br>    self$up = nn_conv_transpose2d(in_size,<br>                                  out_size,<br>                                  kernel_size = <span>2</span>,<br>                                  stride = <span>2</span>)<br>    self$conv_block = conv_block(in_size, out_size)<br>  },<br>  <br>  forward = <span>function</span>(x, bridge) {<br>    <br>    up &lt;- self$up(x)<br>    torch_cat(list(up, bridge), <span>2</span>) %&gt;%<br>      self$conv_block()<br>  }<br>)<br><br>conv_block &lt;- nn_module( <br>  <span>"conv_block"</span>,<br>  <br>  initialize = <span>function</span>(in_size, out_size) {<br>    <br>    self$conv_block &lt;- nn_sequential(<br>      nn_conv2d(in_size, out_size, kernel_size = <span>3</span>, padding = <span>1</span>),<br>      nn_relu(),<br>      nn_dropout(<span>0.6</span>),<br>      nn_conv2d(out_size, out_size, kernel_size = <span>3</span>, padding = <span>1</span>),<br>      nn_relu()<br>    )<br>  },<br>  <br>  forward = <span>function</span>(x){<br>    self$conv_block(x)<br>  }<br>)<br><br><span># 实例化</span><br>device &lt;- torch_device(<span>if</span>(cuda_is_available()) <span>"cuda"</span> <span>else</span> <span>"cpu"</span>)<br>model &lt;- unet(depth = <span>5</span>)$to(device = device)<br></code></pre><section><strong>⑧ </strong><span><strong>设计损失函数以及模型训练</strong></span>：</section><pre data-tool="markdown.com.cn编辑器"><span></span><code>calc_dice_loss &lt;- <span>function</span>(y_pred, y_true) {<br>  <br>  smooth &lt;- <span>1</span><br>  y_pred &lt;- y_pred$view(-<span>1</span>)<br>  y_true &lt;- y_true$view(-<span>1</span>)<br>  intersection &lt;- (y_pred * y_true)$sum()<br>  <br>  <span>1</span> - ((<span>2</span> * intersection + smooth) / (y_pred$sum() + y_true$sum() + smooth))<br>}<br><br>dice_weight &lt;- <span>0.3</span><br><br>optimizer &lt;- optim_sgd(model$parameters, lr = <span>0.1</span>, momentum = <span>0.9</span>)<br><br>num_epochs &lt;- <span>20</span><br><br>scheduler &lt;- lr_one_cycle(<br>  optimizer,<br>  max_lr = <span>0.1</span>,<br>  steps_per_epoch = length(train_dl),<br>  epochs = num_epochs<br>)<br><br>train_batch &lt;- <span>function</span>(b) {<br>  <br>  optimizer$zero_grad()<br>  output &lt;- model(b[[<span>1</span>]]$to(device = device))<br>  target &lt;- b[[<span>2</span>]]$to(device = device)<br>  <br>  bce_loss &lt;- nnf_binary_cross_entropy(output, target)<br>  dice_loss &lt;- calc_dice_loss(output, target)<br>  loss &lt;-  dice_weight * dice_loss + (<span>1</span> - dice_weight) * bce_loss<br>  <br>  loss$backward()<br>  optimizer$step()<br>  scheduler$step()<br><br>  list(bce_loss$item(), dice_loss$item(), loss$item())<br>  <br>}<br><br>valid_batch &lt;- <span>function</span>(b) {<br>  <br>  output &lt;- model(b[[<span>1</span>]]$to(device = device))<br>  target &lt;- b[[<span>2</span>]]$to(device = device)<br><br>  bce_loss &lt;- nnf_binary_cross_entropy(output, target)<br>  dice_loss &lt;- calc_dice_loss(output, target)<br>  loss &lt;-  dice_weight * dice_loss + (<span>1</span> - dice_weight) * bce_loss<br>  <br>  list(bce_loss$item(), dice_loss$item(), loss$item())<br>  <br>}<br><br><span>for</span> (epoch <span>in</span> <span>1</span>:num_epochs) {<br>  <br>  model$train()<br>  train_bce &lt;- c()<br>  train_dice &lt;- c()<br>  train_loss &lt;- c()<br>  <br>  coro::loop(<span>for</span> (b <span>in</span> train_dl) {<br>    c(bce_loss, dice_loss, loss) %&lt;-% train_batch(b)<br>    train_bce &lt;- c(train_bce, bce_loss)<br>    train_dice &lt;- c(train_dice, dice_loss)<br>    train_loss &lt;- c(train_loss, loss)<br>  })<br>  <br>  torch_save(model, paste0(<span>"model_"</span>, epoch, <span>".pt"</span>))<br>  <br>  cat(sprintf(<span>"\nEpoch %d, training: loss:%3f, bce: %3f, dice: %3f\n"</span>,<br>              epoch, mean(train_loss), mean(train_bce), mean(train_dice)))<br>  <br>  model$eval()<br>  valid_bce &lt;- c()<br>  valid_dice &lt;- c()<br>  valid_loss &lt;- c()<br>  <br>  i &lt;- <span>0</span><br>  coro::loop(<span>for</span> (b <span>in</span> tvalid_dl) {<br>    <br>    i &lt;&lt;- i + <span>1</span><br>    c(bce_loss, dice_loss, loss) %&lt;-% valid_batch(b)<br>    valid_bce &lt;- c(valid_bce, bce_loss)<br>    valid_dice &lt;- c(valid_dice, dice_loss)<br>    valid_loss &lt;- c(valid_loss, loss)<br>    <br>  })<br>  <br>  cat(sprintf(<span>"\nEpoch %d, validation: loss:%3f, bce: %3f, dice: %3f\n"</span>,<br>              epoch, mean(valid_loss), mean(valid_bce), mean(valid_dice)))<br>}<br><br><span>#Epoch 1, training: loss:0.304232, bce: 0.148578, dice: 0.667423</span><br><span>#Epoch 1, validation: loss:0.333961, bce: 0.127171, dice: 0.816471</span><br><span>#Epoch 2, training: loss:0.194665, bce: 0.101973, dice: 0.410945</span><br><span>#Epoch 2, validation: loss:0.341121, bce: 0.117465, dice: 0.862983</span><br><span>#[...]</span><br><span>#Epoch 19, training: loss:0.073863, bce: 0.038559, dice: 0.156236</span><br><span>#Epoch 19, validation: loss:0.302878, bce: 0.109721, dice: 0.753577</span><br><span>#Epoch 20, training: loss:0.070621, bce: 0.036578, dice: 0.150055</span><br><span>#Epoch 20, validation: loss:0.295852, bce: 0.101750, dice: 0.748757</span><br></code></pre><section><strong>⑨ </strong><span><strong>模型评估与预测，对未知的样本预测其病变位置</strong></span>：</section><pre data-tool="markdown.com.cn编辑器"><span></span><code>saved_model &lt;- torch_load(<span>"model_20.pt"</span>) <br><br>model &lt;- saved_model<br>model$eval()<br><br><span># without random sampling, we'd mainly see lesion-free patches</span><br>eval_ds &lt;- brainseg_dataset(valid_dir, augmentation_params = <span>NULL</span>, random_sampling = <span>TRUE</span>)<br>eval_dl &lt;- dataloader(eval_ds, batch_size = <span>8</span>)<br><br>batch &lt;- eval_dl %&gt;% dataloader_make_iter() %&gt;% dataloader_next()<br><br>par(mfcol = c(<span>3</span>, <span>8</span>), mar = c(<span>0</span>, <span>1</span>, <span>0</span>, <span>1</span>))<br><br><span>for</span> (i <span>in</span> <span>1</span>:<span>8</span>) {<br>  <br>  img &lt;- batch[[<span>1</span>]][i, .., drop = <span>FALSE</span>]<br>  inferred_mask &lt;- model(img$to(device = device))<br>  true_mask &lt;- batch[[<span>2</span>]][i, .., drop = <span>FALSE</span>]$to(device = device)<br>  <br>  bce &lt;- nnf_binary_cross_entropy(inferred_mask, true_mask)$to(device = <span>"cpu"</span>) %&gt;%<br>    as.numeric()<br>  dc &lt;- calc_dice_loss(inferred_mask, true_mask)$to(device = <span>"cpu"</span>) %&gt;% as.numeric()<br>  cat(sprintf(<span>"\nSample %d, bce: %3f, dice: %3f\n"</span>, i, bce, dc))<br>  <br><br>  inferred_mask &lt;- inferred_mask$to(device = <span>"cpu"</span>) %&gt;% as.array() %&gt;% .[<span>1</span>, <span>1</span>, , ]<br>  <br>  inferred_mask &lt;- ifelse(inferred_mask &gt; <span>0.5</span>, <span>1</span>, <span>0</span>)<br>  <br>  img[<span>1</span>, <span>1</span>, ,] %&gt;% as.array() %&gt;% as.raster() %&gt;% plot()<br>  true_mask$to(device = <span>"cpu"</span>)[<span>1</span>, <span>1</span>, ,] %&gt;% as.array() %&gt;% as.raster() %&gt;% plot()<br>  inferred_mask %&gt;% as.raster() %&gt;% plot()<br>}<br></code></pre><section><img data-galleryid="" data-imgfileid="100011923" data-ratio="0.3638888888888889" data-s="300,640" data-type="png" data-w="1080" data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/LvUIqvYKCeU2uNq5LH4KHSk5kQD9JxTCT4D4bib63dx7gcE0J05me7XlcDdExYBn6KMwfkmjkYJZuSGzodkTdPg/640?wx_fmt=png&amp;from=appmsg" src="https://mmbiz.qpic.cn/sz_mmbiz_png/LvUIqvYKCeU2uNq5LH4KHSk5kQD9JxTCT4D4bib63dx7gcE0J05me7XlcDdExYBn6KMwfkmjkYJZuSGzodkTdPg/640?wx_fmt=png&amp;from=appmsg"></section><p><span><strong><strong>感觉确实灵活？</strong></strong></span></p><section><span></span></section><section><span><strong>大家可以使用试试<strong><img data-ratio="1" data-w="128" data-src="https://res.wx.qq.com/t/wx_fed/we-emoji/res/v1.3.10/assets/newemoji/Yellowdog.png" src="https://res.wx.qq.com/t/wx_fed/we-emoji/res/v1.3.10/assets/newemoji/Yellowdog.png"><img data-ratio="1" data-w="128" data-src="https://res.wx.qq.com/t/wx_fed/we-emoji/res/v1.3.10/assets/Expression/Expression_64@2x.png" src="https://res.wx.qq.com/t/wx_fed/we-emoji/res/v1.3.10/assets/Expression/Expression_64@2x.png"></strong></strong></span></section><section><span><strong>简单分享到这里了</strong></span></section><section><mp-common-profile data-id="MzkyNTIzMzYyMA==" data-pluginname="mpprofile" data-headimg="http://mmbiz.qpic.cn/mmbiz_png/LvUIqvYKCeXYZNMxRMnjiaicO2a27jDZ2FgQga8TdeQcsGRJRIn2IInkKtfcbbMXOBSViaPXpTOBulUlNzd11pzow/0?wx_fmt=png" data-nickname="生信碱移" data-alias="liudoufu307" data-signature="春来秋至，分享我的所见与所识" data-from="2" data-weuitheme="light"></mp-common-profile></section><section><br></section><section><strong><span>END~</span></strong><br></section><p><span><strong>仅供粉丝老铁们参考</strong></span></p><section><strong>如有侵权或错误，请联系删除改正～</strong></section><section data-class="_mbEditor" data-id="32689"><section><section><section><p><span><strong mpa-from-tpl="t">推荐好文，点击查看:</strong></span></p><p><a target="_blank" href="https://mp.weixin.qq.com/s?__biz=MzkyNTIzMzYyMA==&amp;mid=2247491944&amp;idx=1&amp;sn=1f409ad4924e50cc4078cfbf2f8eb90b&amp;scene=21#wechat_redirect" textvalue="【教程】重磅课程代码：神经‍网络预后模型" linktype="text" imgurl="" imgdata="null" data-itemshowtype="0" tab="innerlink" data-linktype="2">【教程】重磅课程代码：神经网络预后模型</a><br></p><p><a target="_blank" href="https://mp.weixin.qq.com/s?__biz=MzkyNTIzMzYyMA==&amp;mid=2247494306&amp;idx=1&amp;sn=9fbb60eba9ed05c0cb6323b6d553d479&amp;scene=21#wechat_redirect" textvalue="【工具】还在用单细胞‍非负矩阵分解吗？广义二值协方差分解+疾病异质性，又是遥遥领先了！（GBCD包）" linktype="text" imgurl="" imgdata="null" data-itemshowtype="0" tab="innerlink" data-linktype="2"><span>【工具】临床基础两手抓！这个12+神经网络模型太贪了，免疫治疗预测、通路重要性、基因重要性、通路交互作用性全部拿下！</span></a></p><p><a target="_blank" href="https://mp.weixin.qq.com/s?__biz=MzkyNTIzMzYyMA==&amp;mid=2247495398&amp;idx=1&amp;sn=ee8b90bc53b8885d39f9005936984f88&amp;scene=21#wechat_redirect" textvalue="【文献】这篇顶刊纯生信领先常规生信分‍析一个版本！" linktype="text" imgurl="" imgdata="null" data-itemshowtype="0" tab="innerlink" data-linktype="2">【文献】Transofomer+图表示学习，16种泛癌的纯数据库深度学习又又又登上顶刊了！</a></p><p><a target="_blank" href="https://mp.weixin.qq.com/s?__biz=MzkyNTIzMzYyMA==&amp;mid=2247495197&amp;idx=1&amp;sn=c62596642fbefba5bb5c6e7070af84f7&amp;scene=21#wechat_redirect" textvalue="【期刊】无版面费低分 SCI 期刊‍，近期发表多篇纯网药研究！" linktype="text" imgurl="" imgdata="null" data-itemshowtype="0" tab="innerlink" data-linktype="2"><span>【期刊】收稿范围广泛！影响因子3+，中科院3区，近期刊登纯生信研究！</span></a></p></section></section></section></section></section><p><mp-style-type data-value="3"></mp-style-type></p></div>  
<hr>
<a href="https://mp.weixin.qq.com/s/nGgAR9bSAplZjxKPX0fLdw",target="_blank" rel="noopener noreferrer">原文链接</a>
