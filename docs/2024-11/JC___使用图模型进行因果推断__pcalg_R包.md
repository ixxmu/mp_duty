---
title: "JC | 使用图模型进行因果推断——pcalg R包"
date: 2024-11-21T09:48:47Z
draft: ["false"]
tags: [
  "fetched",
  "MetLab"
]
categories: ["Acdemic"]
---
JC | 使用图模型进行因果推断——pcalg R包 by MetLab
------
<div><section><section powered-by="xiumi.us"><section><p powered-by="xiumi.us"><br></p><section powered-by="xiumi.us"><section><svg viewbox="0 0 1 1"></svg></section></section><section powered-by="xiumi.us"><section><svg viewbox="0 0 1 1"></svg></section></section><p powered-by="xiumi.us"><br></p><section powered-by="xiumi.us"><p><strong>解读人</strong><strong>：韩昕月</strong></p><p><strong>参考文献：</strong></p><p>M. Kalisch, M. Maechler, D. Colombo, et al. Buehlmann (2012). Causal Inference Using Graphical Models with the R Package pcalg. Journal of Statistical Software 47(11) 1–26, doi: 10.18637/jss.v047.i11.</p></section><section powered-by="xiumi.us"><section><svg viewbox="0 0 1 1"></svg></section></section><section powered-by="xiumi.us"><section><svg viewbox="0 0 1 1"></svg></section></section></section></section><p powered-by="xiumi.us"><br></p><section powered-by="xiumi.us"><p><strong>01</strong></p></section><section powered-by="xiumi.us"><section><section powered-by="xiumi.us"><p><strong>【研究场景】</strong></p></section></section></section><section powered-by="xiumi.us"><p><strong>什么是因果推断？</strong></p><p><span>简单地说，就是判断 X 对 Y 的效应（inferring effect of X on Y）。</span></p><p><strong>为什么要进行因果推断？</strong></p><p><span>Simpson's paradox</span></p><p><span>相关性 ≠ 因果性</span></p><p><strong>Simpson's paradox</strong></p></section><section><section><img data-ratio="0.5039840637450199" data-s="300,640" data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/lRq21FEC3ZYR1icA7otzMQAfbbU1dySzUOhtXX4icyG5ttG9IKZFDicQ1AQnPHQRGcxBPEdU3SiaodP11nibz3usE0g/640?wx_fmt=png" data-type="png" data-w="502" src="https://mmbiz.qpic.cn/sz_mmbiz_png/lRq21FEC3ZYR1icA7otzMQAfbbU1dySzUOhtXX4icyG5ttG9IKZFDicQ1AQnPHQRGcxBPEdU3SiaodP11nibz3usE0g/640?wx_fmt=png"></section></section><section powered-by="xiumi.us"><p><span>假设针对一种流行病有两种治疗方案A与B，根据病情将患者分为轻症和严重患者，关注结果Y为死亡，上面的表展示的是患者死亡率的情况。</span></p><p><span>观察Total列发现，方案A有更低的死亡率，治疗效果比方案B好。</span></p><p><span>然而，考虑到condition这一条件时，发现对于轻症病人治疗方案A的死亡率为15%，而方案B为10%；对于重症病人，治疗方案A的死亡率为30%，而方案B为20%。在不同病情下，方案B是更好的选择，这就是Simpson's paradox。</span></p><p><strong>相关并不意味着因果</strong></p></section><section><section><img data-ratio="0.25" data-s="300,640" data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/lRq21FEC3ZYR1icA7otzMQAfbbU1dySzUpzLolpT4X88JdteksSMtYU0yte1k8rBVIpjEWEFwaNENbwAMjW2uew/640?wx_fmt=png" data-type="png" data-w="508" src="https://mmbiz.qpic.cn/sz_mmbiz_png/lRq21FEC3ZYR1icA7otzMQAfbbU1dySzUpzLolpT4X88JdteksSMtYU0yte1k8rBVIpjEWEFwaNENbwAMjW2uew/640?wx_fmt=png"></section></section><section powered-by="xiumi.us"><p><span>假设有数据表明，大多数穿鞋睡觉的人，起床会头痛；大多数没有穿鞋睡觉的人，起床不会头痛，统计结果显示穿鞋睡觉和起床头痛具有很高的相关性。</span></p><p><span>如果不想起床头痛，晚上睡觉不穿鞋会有用吗？需要判断穿鞋睡觉是否是引起起床头痛的原因。</span></p><p><span>假设有另外数据显示，穿鞋睡觉的人大多数都喝多了，且第二天头痛的人大多数也是这些人。可能说明，导致穿鞋睡觉和起床头痛的高相关性是因为他们有一个共同因素就是：喝多了。</span></p></section><section><section><img data-ratio="0.6167023554603854" data-s="300,640" data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/lRq21FEC3ZYR1icA7otzMQAfbbU1dySzUcXRPTyiao9x9wZwcjOAZLv4ic8N0MsyUJOarUy5rHI1eApzOD5tG7xBQ/640?wx_fmt=png" data-type="png" data-w="467" src="https://mmbiz.qpic.cn/sz_mmbiz_png/lRq21FEC3ZYR1icA7otzMQAfbbU1dySzUcXRPTyiao9x9wZwcjOAZLv4ic8N0MsyUJOarUy5rHI1eApzOD5tG7xBQ/640?wx_fmt=png"></section></section><section><section><img data-ratio="0.5667870036101083" data-s="300,640" data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/lRq21FEC3ZYR1icA7otzMQAfbbU1dySzUBn2z3bMGyZVcBmyInMUOKEWCFrISwqsgPalAUExveeRRVzq2V7cL5g/640?wx_fmt=png" data-type="png" data-w="554" src="https://mmbiz.qpic.cn/sz_mmbiz_png/lRq21FEC3ZYR1icA7otzMQAfbbU1dySzUBn2z3bMGyZVcBmyInMUOKEWCFrISwqsgPalAUExveeRRVzq2V7cL5g/640?wx_fmt=png"></section></section><section powered-by="xiumi.us"><p><strong>穿鞋睡觉和起床头痛之间有很高相关性的可能原因：</strong></p><p><span>1.两组人群有很大的异质性：穿鞋睡觉的人基本都喝多了，而没穿鞋睡觉的人基本没喝多，所以这两组人群本身是不可比的，无法进行因果推断。</span></p><p><span>2.confounder（混杂）：由于存在共同原因即喝多了，混淆了两个变量的相关性。</span></p><p><span>如上图所示，confounder会导致观测数据存在confounding association。而我们观测到的数据，存在这两种混合的相关性。由于confounding association的存在，观测到的混合相关性无法直接推测出因果关系，所以相关性与因果性不同，也无法推出因果性。</span></p><p><strong>什么样的关系才能用因果来表示呢？</strong></p></section><section powered-by="xiumi.us"><p>先通过一个例子来介绍Potential outcomes的概念。前面说因果推断就是推测某个treatment针对某个outcome的效应。以起床头疼举例，那么起床是否头疼就是结果Y∈{0，1}，研究对象为试验T（比如是否吃药）。</p><p>当吃药不头疼了，不吃药头还疼，会认为吃药和解决头疼可能存在因果效应。</p></section><section><section><img data-ratio="0.3435804701627486" data-s="300,640" data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/lRq21FEC3ZYR1icA7otzMQAfbbU1dySzUBp9Cx3bvZjmkUm3mpMtwrEpEdS2ibe5bGwU1q6jOic5O2ZwD3Gpibeo6g/640?wx_fmt=png" data-type="png" data-w="553" src="https://mmbiz.qpic.cn/sz_mmbiz_png/lRq21FEC3ZYR1icA7otzMQAfbbU1dySzUBp9Cx3bvZjmkUm3mpMtwrEpEdS2ibe5bGwU1q6jOic5O2ZwD3Gpibeo6g/640?wx_fmt=png"></section></section><section powered-by="xiumi.us"><p>当吃不吃药头都疼，则认为吃药和解决头疼不存在因果效应。</p></section><section><section><img data-ratio="0.34594594594594597" data-s="300,640" data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/lRq21FEC3ZYR1icA7otzMQAfbbU1dySzUgtn05yorXU3cfNWeooT733VtAhibuxg3wWDAxQJq2ricib0zGicos3q8Bw/640?wx_fmt=png" data-type="png" data-w="555" src="https://mmbiz.qpic.cn/sz_mmbiz_png/lRq21FEC3ZYR1icA7otzMQAfbbU1dySzUgtn05yorXU3cfNWeooT733VtAhibuxg3wWDAxQJq2ricib0zGicos3q8Bw/640?wx_fmt=png"></section></section><section powered-by="xiumi.us"><p><span>所以可以由此引出因果效应的计算方法。即do(T=1)为施加试验(吃药)，do(T=0)为不施加试验(不吃药)；Y表示结果(是否头疼)。则潜在结果就是do(T=1)的结果Y(i)|(do(T=1))与do(T=0)的结果Y(i)|(do(T=0))。</span></p></section><section><section><img data-ratio="0.838150289017341" data-s="300,640" data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/lRq21FEC3ZYR1icA7otzMQAfbbU1dySzUTm0Cia9qRjVEzGjicH4I5PjSwj3cG6XH0hzBeYrkgpZia6Gtiau2iaHd5Aw/640?wx_fmt=png" data-type="png" data-w="519" src="https://mmbiz.qpic.cn/sz_mmbiz_png/lRq21FEC3ZYR1icA7otzMQAfbbU1dySzUTm0Cia9qRjVEzGjicH4I5PjSwj3cG6XH0hzBeYrkgpZia6Gtiau2iaHd5Aw/640?wx_fmt=png"></section></section><section powered-by="xiumi.us"><p>因此，因果效应为Y(i)|(do(T=1)) - Y(i)|(do(T=0))，代表施加与不施加试验 结果的差异。这是针对某个人i的因果效应，称为ITE (Individual treatment effect)。</p><p><strong>因果推断的基本问题</strong></p><p><span>针对某个人，对其施加 treatment，就无法观察到不施加 treatment 的结果。只能得到 potential outcomes 中的一个结果，另一个称为反事实 (counterfactual) 。因为无法观测到 counterfactual，所以无法计算 ITE。</span></p><p><span>因此，希望能计算针对人群的平均效应 ATE (Average treatment effect)。</span></p><p><span>E[Y(i)(1) - Y(i)(0)] = E[Y(i)(1)] – E[Y(i)(0)]</span></p><p><span>上式是一个因果效应的计算（期望的线性性质）。但为了统计计算方便希望计算针对试验的条件期望，但这往往是不相等的。</span></p><p><span>E[Y(i)(1)] – E[Y(i)(0)] ≠ E[Y(i)|T=1] - E[Y(i)|T=0]</span></p><p><span>因为等号右边衡量的是相关性（基于统计），前面讲了由于存在 confounding association，相关性无法推出因果性（等号左边）。</span></p></section><section powered-by="xiumi.us"><p><strong><span>随机对照试验</span></strong></p><p>当存在 confounding 时，无法通过条件期望计算因果效应 (ATE) 。假如不存在 confounding association，则可以计算因果效应。一种方法是没有额外因素来影响试验 T，也就是随机对照试验（treatment 完全随机决定）。</p></section><section><section><img data-ratio="0.5785123966942148" data-s="300,640" data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/lRq21FEC3ZYR1icA7otzMQAfbbU1dySzUAjZALvNibG3mCZFnricXvicKHPVqQFLmibfveqFFMU4NUxB01MVjuuzzhA/640?wx_fmt=png" data-type="png" data-w="363" src="https://mmbiz.qpic.cn/sz_mmbiz_png/lRq21FEC3ZYR1icA7otzMQAfbbU1dySzUAjZALvNibG3mCZFnricXvicKHPVqQFLmibfveqFFMU4NUxB01MVjuuzzhA/640?wx_fmt=png"></section></section><section powered-by="xiumi.us"><p><strong>随机对照试验特点:</strong></p><p><span>1.试验完全由随机决定（T 无 causal parents ）</span></p><p><span>2.此时 treatment 组和 control 组是 causal parents 可比的（其他因素在两个组分布均匀）</span></p><p><span>3.此时可以通过条件期望计算因果效应</span></p><p><span>4.存在其他未观测 confounding 时，只要进行随机试验，就可以计算因果效应</span></p><p><span>No confounding：E[Y(i)(1)] – E[Y(i)(0)] = E[Y(i)|T=1] - E[Y(i)|T=0]</span></p><p><strong>观察性研究</strong></p><p><span>虽然随机对照试验是计算因果效应的理想方案，但在现实世界中，可能由于种种原因（ 伦理学、可行性等）是无法进行的，而从观察性研究（Observational studies）获得的数据中推断因果关系，具有更大的意义。</span></p></section><section><section><img data-ratio="0.9257731958762887" data-s="300,640" data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/lRq21FEC3ZYR1icA7otzMQAfbbU1dySzUt5wTEnkd771n0kGXTt8HOxEW77evOibWQNzIgamQD9Lv4mfibnZPTG3Q/640?wx_fmt=png" data-type="png" data-w="485" src="https://mmbiz.qpic.cn/sz_mmbiz_png/lRq21FEC3ZYR1icA7otzMQAfbbU1dySzUt5wTEnkd771n0kGXTt8HOxEW77evOibWQNzIgamQD9Lv4mfibnZPTG3Q/640?wx_fmt=png"></section></section><section powered-by="xiumi.us"><p>但观察性研究中往往包含confounding association，混淆了变量之间的相关性，如何研究其因果效应呢？</p><p><strong><span>后门准则和前门准则</span></strong></p><p>因果推断的观察性研究直接问题就是存在confounders,对其进行处理分析，进而进行因果推断。可以通过后门准则和前门准则去阻断confounder → Y这个路径，把casual association分离出来。</p></section><section><section><img data-ratio="0.6024258760107817" data-s="300,640" data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/lRq21FEC3ZYR1icA7otzMQAfbbU1dySzU23zmJUHKibxicKw9NxVDqKE5rOmytj1icicWZkGibibYUZhXWP4g0Lvem69g/640?wx_fmt=png" data-type="png" data-w="742" src="https://mmbiz.qpic.cn/sz_mmbiz_png/lRq21FEC3ZYR1icA7otzMQAfbbU1dySzU23zmJUHKibxicKw9NxVDqKE5rOmytj1icicWZkGibibYUZhXWP4g0Lvem69g/640?wx_fmt=png"></section></section><section powered-by="xiumi.us"><p>后门准则（backdoor criterion）和前门准则（frontdoor criterion）。这两个准则的意义在于：（1）某些研究中，即使关系图中的某些变量不可观测，依然可以从观测数据中估计出某些因果作用；（2）这两个准则有助于我们鉴别“混杂变量”和设计观察性研究。</p><p><span>前面COVID-27例子，基于上述方法计算可得，在这个因果结构（存在confounder）下，Treatment B更好。</span></p></section><section><section><img data-ratio="0.38461538461538464" data-s="300,640" data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/lRq21FEC3ZYR1icA7otzMQAfbbU1dySzUc3PGYxcXpOqD5JDqLeliaXZWUBcXOIFsQ7acLl6fu2bicckdfhD2WkOw/640?wx_fmt=png" data-type="png" data-w="832" src="https://mmbiz.qpic.cn/sz_mmbiz_png/lRq21FEC3ZYR1icA7otzMQAfbbU1dySzUc3PGYxcXpOqD5JDqLeliaXZWUBcXOIFsQ7acLl6fu2bicckdfhD2WkOw/640?wx_fmt=png"></section></section><section powered-by="xiumi.us"><p>可以发现，Simpson's Paradox的存在就是因为计算过程中Treatment和Control组中不同的严重程度（confounder）分配权重是不同的，两个组内confounder因素存在差异，导致不可比。根据上式计算可以发现，实验组和对照组中confounder的权重都是一样的，所以计算是合理的。</p></section><p powered-by="xiumi.us"><br></p><section powered-by="xiumi.us"><p><strong>02</strong></p></section><section powered-by="xiumi.us"><section><section powered-by="xiumi.us"><p><strong>【研究方法】</strong></p></section></section></section><section powered-by="xiumi.us"><p><strong>概率图模型</strong></p></section><section powered-by="xiumi.us"><p>对于一个 K 维随机向量 X = [X(1), X(2), ……, X(k)](T)一般难以直接建模。因为如果每个变量为离散变量并有 M 个可能取值，在不作任何独立性假设的前提下，需要 M(K)−1 个参数才能表示其概率分布，参数数量会非常庞大。</p><p>一种减少参数数量的方法是独立性假设。把 X 的联合概率分解为 K 个条件概率的乘积：</p></section><section><section><img data-ratio="0.2003968253968254" data-s="300,640" data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/lRq21FEC3ZYR1icA7otzMQAfbbU1dySzUGZdg73sAibOBp9Lc0c5a7GRn5rKVE7aSVupbEEt89W3Vo6GPVy6kMDA/640?wx_fmt=png" data-type="png" data-w="504" src="https://mmbiz.qpic.cn/sz_mmbiz_png/lRq21FEC3ZYR1icA7otzMQAfbbU1dySzUGZdg73sAibOBp9Lc0c5a7GRn5rKVE7aSVupbEEt89W3Vo6GPVy6kMDA/640?wx_fmt=png"></section></section><section powered-by="xiumi.us"><p>x 为随机向量 X 的取值。可以看到，如果某些变量之间存在条件独立，参数数量就可以大幅减少。</p><p>因此，概率图模型（Probabilistic Graphical Model，PGM）用图结构来描述多元随机变量之间的条件独立关系，从而为研究高维空间中的概率模型带来了很大的便捷。</p><p><strong><span>有向图模型 &amp; 无向图模型</span></strong></p><p>概率图模型中，每个节点表示一个（或一组）随机变量，边表示这些随机变量之间的概率依赖关系。常见的概率图模型可以分为有向图模型和无向图模型。</p></section><section><section><img data-ratio="0.6011904761904762" data-s="300,640" data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/lRq21FEC3ZYR1icA7otzMQAfbbU1dySzU29ncEeSat10ulTBPHfp5pDgvfy7HhpiaHVzlJ7a4qulh9sb4Oibv0SGw/640?wx_fmt=png" data-type="png" data-w="336" src="https://mmbiz.qpic.cn/sz_mmbiz_png/lRq21FEC3ZYR1icA7otzMQAfbbU1dySzU29ncEeSat10ulTBPHfp5pDgvfy7HhpiaHVzlJ7a4qulh9sb4Oibv0SGw/640?wx_fmt=png"></section></section><section powered-by="xiumi.us"><p>有向图模型，也称为贝叶斯网络（Bayesian Network），使用有向无环图（Directed Acyclic Graph，DAG）来描述变量之间的关系。如果两个节点之间有连边，表示两个变量之间有因果关系，即不存在其他变量使得这两个变量条件独立。</p></section><section><section><img data-ratio="0.6133720930232558" data-s="300,640" data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/lRq21FEC3ZYR1icA7otzMQAfbbU1dySzUOibV1rMUk9sMRaPRzRskkUqZNCR2Y71ibdgiaOGG9ibQxJCqMouWq3AM4Q/640?wx_fmt=png" data-type="png" data-w="344" src="https://mmbiz.qpic.cn/sz_mmbiz_png/lRq21FEC3ZYR1icA7otzMQAfbbU1dySzUOibV1rMUk9sMRaPRzRskkUqZNCR2Y71ibdgiaOGG9ibQxJCqMouWq3AM4Q/640?wx_fmt=png"></section></section><section powered-by="xiumi.us"><p>无向图模型，也称为马尔可夫随机场（Markov Random Field，MRF），使用无向图来描述变量之间的关系。两个节点之间有连边代表这两个变量之间有概率依赖关系，但不一定是因果关系。</p><p><strong><span>贝叶斯网络</span></strong></p><p>有向无环图 G 中，每个节点对应 K 维随机向量 X 中的一个变量，有向边 e(ij )表示随机变量 X(i )和 X(j )之间具有因果关系，父节点 Xi 是因，子节点 Xj 是果，显然这两个点之间一定非条件独立。<br></p><p>令 X(πk )为变量 Xk 的所有父节点变量集合，P(X(k)∣X(πk)) 表示每个随机变量的局部条件概率分布（Local Conditional Probability Distribution）。</p><p>如果 X 的联合概率分布可以分解为每个随机变量 X(k )的局部条件概率的连乘形式，即：</p></section><section><section><img data-ratio="0.30714285714285716" data-s="300,640" data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/lRq21FEC3ZYR1icA7otzMQAfbbU1dySzU8AsBBEWHF9NibcYyAj8ykXIfm2nwfMXXNZ5t5HzGqyhHevROlxdmYGQ/640?wx_fmt=png" data-type="png" data-w="280" src="https://mmbiz.qpic.cn/sz_mmbiz_png/lRq21FEC3ZYR1icA7otzMQAfbbU1dySzU8AsBBEWHF9NibcYyAj8ykXIfm2nwfMXXNZ5t5HzGqyhHevROlxdmYGQ/640?wx_fmt=png"></section></section><section powered-by="xiumi.us"><p> 那么称 (G, X) 构成了一个贝叶斯网络。</p><p><strong><span>PC 算法</span></strong></p><p>PC 算法可以用来学习贝叶斯网络的结构。先确定节点间的依赖关系（但不确定方向），即先生成一个无向图，然后再确定依赖方向，把无向图扩展为完全部分有向无环图（Completed Partially Directed Acyclic Graph，CPDAG）。</p><p>首先是依赖关系确立：</p><p>设 V 是输入点集，有以下步骤：</p><p>1.在 V 上生成完全无向图 G；</p><p>2.对于 G 中的两个相邻点 i , j，如果 i 和 j 能在给定节点 k 时条件独立，则删除 i 和 j 之间的边。</p><p>这样会得到一个无向图，无向边表示它连接的两个节点之间有依赖（因果）关系，这样的无向图叫骨架（skeleton）。</p><p><strong><span>依赖关系方向确立</span></strong></p><p>经过上述阶段，获得无向图，然后利用 d-separation 来确定图中边的依赖方向，把骨架扩展为 DAG。</p><p>d-separation 是一种用来判断变量是否条件独立的图形化方法，相比于非图形化方法，更加直观，且计算简单。对于一个 DAG，d-separation 方法可以快速的判断出两个节点之间是否是条件独立的。</p><p>节点集合 O 能 d-separation 节点 i 与节点 j ，当且仅当：</p><p>给定 O 时，i 与 j 之间不存在有效路径（active path），即 i 和 j 在 O 下条件独立（记作 i⊥j∣O），用 O (i, j) 表示能够 d-separation i 和 j 的点集。</p><p>对于任意三个以有效依赖关系边相连的节点 X−Z−Y，其依赖关系必为下图的四种关系之一：</p></section><section><section><img data-ratio="0.5193798449612403" data-s="300,640" data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/lRq21FEC3ZYR1icA7otzMQAfbbU1dySzUQbu7tIiaPMgbDmIyXgFXfbUspenl41xUyUTf6Ksgc0EcUxFhhkic845w/640?wx_fmt=png" data-type="png" data-w="516" src="https://mmbiz.qpic.cn/sz_mmbiz_png/lRq21FEC3ZYR1icA7otzMQAfbbU1dySzUQbu7tIiaPMgbDmIyXgFXfbUspenl41xUyUTf6Ksgc0EcUxFhhkic845w/640?wx_fmt=png"></section></section><section powered-by="xiumi.us"><p>路径中存在某个节点 Z 是 head-to-tial（图中情况 a, b）或 tail-to-tail 节点（图中情况 c），且 Z 包含在 O 中；</p><p>路径中存在某个节点 Z 是 head-to-head 节点（图中情况 d），且 Z 没有被包含在 O 中；</p><p>如果 X,Y 间所有的路径都是阻塞的，那么 X,Y 关于 O 条件独立；否则，X,Y 不关于 O 条件独立。</p><p><strong><span>PC 算法概述</span></strong></p></section><section><section><img data-ratio="0.4276595744680851" data-s="300,640" data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/lRq21FEC3ZYR1icA7otzMQAfbbU1dySzUlOqKPkNbmeFQM1jsoIKoCBENGj5HeoFDrRShnWPVkULaJAVuFKYiadA/640?wx_fmt=png" data-type="png" data-w="940" src="https://mmbiz.qpic.cn/sz_mmbiz_png/lRq21FEC3ZYR1icA7otzMQAfbbU1dySzUlOqKPkNbmeFQM1jsoIKoCBENGj5HeoFDrRShnWPVkULaJAVuFKYiadA/640?wx_fmt=png"></section></section><section powered-by="xiumi.us"><p><strong><span>PC算法检验条件独立性的具体流程</span></strong></p></section><section><section><img data-ratio="0.6732673267326733" data-s="300,640" data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/lRq21FEC3ZYR1icA7otzMQAfbbU1dySzUicHyaib0Rc3Df3oqeUB7Tzs4ona9K3xyRSRTvYvULnllmBwNpfnsicMjg/640?wx_fmt=png" data-type="png" data-w="404" src="https://mmbiz.qpic.cn/sz_mmbiz_png/lRq21FEC3ZYR1icA7otzMQAfbbU1dySzUicHyaib0Rc3Df3oqeUB7Tzs4ona9K3xyRSRTvYvULnllmBwNpfnsicMjg/640?wx_fmt=png"></section></section><section powered-by="xiumi.us"><p><strong><span>马尔科夫等价类</span></strong></p><p>如下图，有向无环图 G(1)=（V, E(1)）和 G(2)=（V, E(2)）有相同的顶点集合和骨架，V 为顶点集合，E(1) 和 E(2) 为边的集合。</p><p>对于任意不相交的顶点集合 A, B, C ∈ V，如果满足 A, B 在 G(1) 和 G(2 )中都被 C 所 d-separation（也叫有相同的 V 结构），则称图 G(1) 和 G(2) 是马尔科夫等价的。</p></section><section><section><img data-ratio="0.42115384615384616" data-s="300,640" data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/lRq21FEC3ZYR1icA7otzMQAfbbU1dySzUPJ724LB5wpSq0aNLvhnfnmbXeXic2wOVcaOhzwbW3HZiciafKwTyt0r3g/640?wx_fmt=png" data-type="png" data-w="520" src="https://mmbiz.qpic.cn/sz_mmbiz_png/lRq21FEC3ZYR1icA7otzMQAfbbU1dySzUPJ724LB5wpSq0aNLvhnfnmbXeXic2wOVcaOhzwbW3HZiciafKwTyt0r3g/640?wx_fmt=png"></section></section><section powered-by="xiumi.us"><p>上图G(1)和G(2)是马尔科夫等价类，它们左上角的那条有向边方向并不相同，这时PC算法就无法判断这条边的方向了，只能输出无向边，即G(3)。</p><p>所以，严格来说，PC算法以及大多数基于依赖统计分析的贝叶斯网络结构学习算法，得到的都只是一个CPDAG（依然有无向边），而不是真正意义上的贝叶斯网络（有向无环图）。</p><p><strong><span>绘制因果图</span></strong></p><p><strong><span>使用非实验数据画因果图的方法主要可以分为三类</span></strong></p><p>1. Constraint-based Algorithms，常见算法：PC 和变种、FCI、GFCI、RFCI……<br></p><p>2. Score-based Algorithms，常见算法：Greedy Equivalence Search (GES)、FGES……</p><p>3. Algorithms based on Functional Causal Models (FCMs)，常见算法：Linear Non-Gaussian Acyclic Model (LiNGAM)、ICA-LiNGAM……</p><p><strong><span>几个算法简要介绍</span></strong></p><p><strong><span></span></strong></p></section><section><section><img data-ratio="0.625" data-s="300,640" data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/lRq21FEC3ZYR1icA7otzMQAfbbU1dySzUbFBM2RIYG8EtWHPbvKOoWfibqWuE4SRKRKc4icdxPgjRRIlfRrrNIqjg/640?wx_fmt=png" data-type="png" data-w="912" src="https://mmbiz.qpic.cn/sz_mmbiz_png/lRq21FEC3ZYR1icA7otzMQAfbbU1dySzUbFBM2RIYG8EtWHPbvKOoWfibqWuE4SRKRKc4icdxPgjRRIlfRrrNIqjg/640?wx_fmt=png"></section></section><section powered-by="xiumi.us"><p><strong><span>开源工具</span></strong></p><p>pcalg包、Tetrad、CausalDiscoveryToolbox （Python）</p><p><strong><span>开源工具的优缺点比较</span></strong></p></section><section><section><img data-ratio="0.4564814814814815" data-s="300,640" data-src="https://mmbiz.qpic.cn/sz_mmbiz_png/lRq21FEC3ZYR1icA7otzMQAfbbU1dySzUwdVkNlibTNMNWBBiafoQ6g9YdvxDUjJvLVrWkvrt8l8xcoGcUIs96Jaw/640?wx_fmt=png" data-type="png" data-w="1080" src="https://mmbiz.qpic.cn/sz_mmbiz_png/lRq21FEC3ZYR1icA7otzMQAfbbU1dySzUwdVkNlibTNMNWBBiafoQ6g9YdvxDUjJvLVrWkvrt8l8xcoGcUIs96Jaw/640?wx_fmt=png"></section></section><section powered-by="xiumi.us"><p><strong><span>Ref：</span></strong></p><p><span>M. Kalisch, M. Maechler, D. Colombo, M.H. Maathuis and P. Buehlmann (2012). Causal Inference Using Graphical Models with the R Package pcalg. Journal of Statistical Software 47(11) 1–26, doi: 10.18637/jss.v047.i11.</span></p><p><span>M. Kalisch and P. Buehlmann (2007). Estimating high-dimensional directed acyclic graphs with the PC-algorithm. JMLR 8 613-636.</span></p><p><span>https://www.dango.rocks/blog/2019/09/24/Causality5-Drawing-Causal-Diagram/</span></p><p><span>https://www.zhihu.com/people/tinky2013/posts?page=1</span></p><p><span>https://www.bradyneal.com/causal-inference-course</span></p><p><span>https://zhuanlan.zhihu.com/p/269625734</span></p><p><span>https://www.zhihu.com/people/a-meng-1-71/posts?page=1</span></p><p><span>https://blog.zxh.io/post/2021/04/26/pc-algorithm/</span></p></section><section powered-by="xiumi.us"><p><strong><span>补：边的定向规则</span></strong></p><p>基于依赖分析的贝叶斯网络结构学习方法一般具有以下基本程序：(1)将一个完全无向图 G 初始化；(2)在 G 中，每一对相邻节点 X，Y，假若可以寻找到一个分割集 S ，使得节点 X, Y之间满足 X ⊥Y |S，则将 X，Y之间的边移除，并且将分割集 S 标记为 Sepset(X，Y)  。否则，对X, Y不做出任何的处理；(3)在最后得到的结构图G中定向。即对于每一个三元组&lt; X, Z, Y&gt;, 假若满足Z∉Sepset( X, Y )  ，并且X, Y之间不相邻，则将这个三元组的方向定为<span>X →Z ←Y ；</span><span>一直做这样的定向规则，直到再也不能进行定向为止。</span></p><p>对边的定向具有如下的规则：</p><p>i) 没有新的 V-结构增加时，即假若X， Y之间不相邻，并且有X →Z — Y ，则所定的方向为X →Z →Y；</p><p>ii) 应该避免有向圈的形成，即假若X， Y之间是相邻的，并且存在了一条X， Y之间的有向路X→ W→ Z→ Y，则对其的方向定为X→Y ；</p><p>iii) 需要避免新的V-结构和有向圈这两种情况同时的发生，也即假如存在X →Z ←Y ，并且X— W— Y ， Z— W，同时存在X， Y之间是不相邻的，则将其方向定为W→ Z ．否则会出现在避免有向圈形成的时候出现一个新的V-结构，而在避免新的V-结构出现的时候会形成有向圈。</p></section><p powered-by="xiumi.us"><br></p><p powered-by="xiumi.us"><span><span data-raw-text="【" data-textnode-index-1669343972674="63" data-index-1669343972674="4325" data-textnode-notemoji-index-1669343972674="4325">【</span><span data-raw-text="M" data-textnode-index-1669343972674="63" data-index-1669343972674="4326" data-textnode-notemoji-index-1669343972674="4326">M</span><span data-raw-text="e" data-textnode-index-1669343972674="63" data-index-1669343972674="4327" data-textnode-notemoji-index-1669343972674="4327">e</span><span data-raw-text="t" data-textnode-index-1669343972674="63" data-index-1669343972674="4328" data-textnode-notemoji-index-1669343972674="4328">t</span><span data-raw-text="L" data-textnode-index-1669343972674="63" data-index-1669343972674="4329" data-textnode-notemoji-index-1669343972674="4329">L</span><span data-raw-text="A" data-textnode-index-1669343972674="63" data-index-1669343972674="4330" data-textnode-notemoji-index-1669343972674="4330">A</span><span data-raw-text="B" data-textnode-index-1669343972674="63" data-index-1669343972674="4331" data-textnode-notemoji-index-1669343972674="4331">B</span><span data-raw-text="公" data-textnode-index-1669343972674="63" data-index-1669343972674="4332" data-textnode-notemoji-index-1669343972674="4332">公</span><span data-raw-text="众" data-textnode-index-1669343972674="63" data-index-1669343972674="4333" data-textnode-notemoji-index-1669343972674="4333">众</span><span data-raw-text="号" data-textnode-index-1669343972674="63" data-index-1669343972674="4334" data-textnode-notemoji-index-1669343972674="4334">号</span><span data-raw-text="同" data-textnode-index-1669343972674="63" data-index-1669343972674="4335" data-textnode-notemoji-index-1669343972674="4335">同</span><span data-raw-text="期" data-textnode-index-1669343972674="63" data-index-1669343972674="4336" data-textnode-notemoji-index-1669343972674="4336">期</span><span data-raw-text="推" data-textnode-index-1669343972674="63" data-index-1669343972674="4337" data-textnode-notemoji-index-1669343972674="4337">推</span><span data-raw-text="送" data-textnode-index-1669343972674="63" data-index-1669343972674="4338" data-textnode-notemoji-index-1669343972674="4338">送</span></span><strong><span data-raw-text="J" data-textnode-index-1669343972674="64" data-index-1669343972674="4339" data-textnode-notemoji-index-1669343972674="4339">J</span><span data-raw-text="C" data-textnode-index-1669343972674="64" data-index-1669343972674="4340" data-textnode-notemoji-index-1669343972674="4340">C</span><span data-raw-text="文" data-textnode-index-1669343972674="64" data-index-1669343972674="4341" data-textnode-notemoji-index-1669343972674="4341">文</span><span data-raw-text="献" data-textnode-index-1669343972674="64" data-index-1669343972674="4342" data-textnode-notemoji-index-1669343972674="4342">献</span><span data-raw-text="分" data-textnode-index-1669343972674="64" data-index-1669343972674="4343" data-textnode-notemoji-index-1669343972674="4343">分</span><span data-raw-text="享" data-textnode-index-1669343972674="64" data-index-1669343972674="4344" data-textnode-notemoji-index-1669343972674="4344">享</span><span data-raw-text="会" data-textnode-index-1669343972674="64" data-index-1669343972674="4345" data-textnode-notemoji-index-1669343972674="4345">会</span><span data-raw-text="预" data-textnode-index-1669343972674="64" data-index-1669343972674="4346" data-textnode-notemoji-index-1669343972674="4346">预</span><span data-raw-text="告" data-textnode-index-1669343972674="64" data-index-1669343972674="4347" data-textnode-notemoji-index-1669343972674="4347">告</span></strong><span><span data-raw-text="，" data-textnode-index-1669343972674="65" data-index-1669343972674="4348" data-textnode-notemoji-index-1669343972674="4348">，</span><span data-raw-text="感" data-textnode-index-1669343972674="65" data-index-1669343972674="4349" data-textnode-notemoji-index-1669343972674="4349">感</span><span data-raw-text="兴" data-textnode-index-1669343972674="65" data-index-1669343972674="4350" data-textnode-notemoji-index-1669343972674="4350">兴</span><span data-raw-text="趣" data-textnode-index-1669343972674="65" data-index-1669343972674="4351" data-textnode-notemoji-index-1669343972674="4351">趣</span><span data-raw-text="的" data-textnode-index-1669343972674="65" data-index-1669343972674="4352" data-textnode-notemoji-index-1669343972674="4352">的</span><span data-raw-text="老" data-textnode-index-1669343972674="65" data-index-1669343972674="4353" data-textnode-notemoji-index-1669343972674="4353">老</span><span data-raw-text="师" data-textnode-index-1669343972674="65" data-index-1669343972674="4354" data-textnode-notemoji-index-1669343972674="4354">师</span><span data-raw-text="同" data-textnode-index-1669343972674="65" data-index-1669343972674="4355" data-textnode-notemoji-index-1669343972674="4355">同</span><span data-raw-text="学" data-textnode-index-1669343972674="65" data-index-1669343972674="4356" data-textnode-notemoji-index-1669343972674="4356">学</span><span data-raw-text="可" data-textnode-index-1669343972674="65" data-index-1669343972674="4358" data-textnode-notemoji-index-1669343972674="4358">可</span><span data-raw-text="以" data-textnode-index-1669343972674="65" data-index-1669343972674="4359" data-textnode-notemoji-index-1669343972674="4359">以</span><span data-raw-text="点" data-textnode-index-1669343972674="65" data-index-1669343972674="4360" data-textnode-notemoji-index-1669343972674="4360">点</span><span data-raw-text="击" data-textnode-index-1669343972674="65" data-index-1669343972674="4361" data-textnode-notemoji-index-1669343972674="4361">击</span><span data-raw-text="同" data-textnode-index-1669343972674="65" data-index-1669343972674="4362" data-textnode-notemoji-index-1669343972674="4362">同</span><span data-raw-text="期" data-textnode-index-1669343972674="65" data-index-1669343972674="4363" data-textnode-notemoji-index-1669343972674="4363">期</span><span data-raw-text="推" data-textnode-index-1669343972674="65" data-index-1669343972674="4364" data-textnode-notemoji-index-1669343972674="4364">推</span><span data-raw-text="送" data-textnode-index-1669343972674="65" data-index-1669343972674="4365" data-textnode-notemoji-index-1669343972674="4365">送</span></span><strong><span data-raw-text="最" data-textnode-index-1669343972674="66" data-index-1669343972674="4367" data-textnode-notemoji-index-1669343972674="4367">最</span><span data-raw-text="后" data-textnode-index-1669343972674="66" data-index-1669343972674="4368" data-textnode-notemoji-index-1669343972674="4368">后</span><span data-raw-text="一" data-textnode-index-1669343972674="66" data-index-1669343972674="4369" data-textnode-notemoji-index-1669343972674="4369">一</span><span data-raw-text="条" data-textnode-index-1669343972674="66" data-index-1669343972674="4370" data-textnode-notemoji-index-1669343972674="4370">条</span><span data-raw-text="消" data-textnode-index-1669343972674="66" data-index-1669343972674="4371" data-textnode-notemoji-index-1669343972674="4371">消</span><span data-raw-text="息" data-textnode-index-1669343972674="66" data-index-1669343972674="4372" data-textnode-notemoji-index-1669343972674="4372">息</span></strong><span><span data-raw-text="查" data-textnode-index-1669343972674="67" data-index-1669343972674="4373" data-textnode-notemoji-index-1669343972674="4373">查</span><span data-raw-text="看" data-textnode-index-1669343972674="67" data-index-1669343972674="4374" data-textnode-notemoji-index-1669343972674="4374">看</span><span data-raw-text="】" data-textnode-index-1669343972674="67" data-index-1669343972674="4375" data-textnode-notemoji-index-1669343972674="4375">】</span></span></p><p powered-by="xiumi.us"><br></p></section><p><br></p><p><mp-style-type data-value="3"></mp-style-type></p></div>  
<hr>
<a href="https://mp.weixin.qq.com/s/-2BguXJrtnsk0FWqZzRqBQ",target="_blank" rel="noopener noreferrer">原文链接</a>
