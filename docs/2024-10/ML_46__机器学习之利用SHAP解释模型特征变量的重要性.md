---
title: "ML 46. 机器学习之利用SHAP解释模型特征变量的重要性"
date: 2024-10-25T07:13:20Z
draft: ["false"]
tags: [
  "fetched",
  "桓峰基因"
]
categories: ["Acdemic"]
---
ML 46. 机器学习之利用SHAP解释模型特征变量的重要性 by 桓峰基因
------
<div><p><img data-imgfileid="100011016" data-ratio="0.4267326732673267" data-src="https://mmbiz.qpic.cn/mmbiz_png/5ia62S5YZaMxdjEsWs1Shxy54alETSRmMmPUlia8ajqVjDDSOicd4BTWT2lUAFqz3P660MFWt5tqx8TrH4Yy67GtQ/640?wx_fmt=other&amp;wxfrom=5&amp;wx_lazy=1&amp;wx_co=1&amp;tp=webp" data-w="1010" src="https://mmbiz.qpic.cn/mmbiz_png/5ia62S5YZaMxdjEsWs1Shxy54alETSRmMmPUlia8ajqVjDDSOicd4BTWT2lUAFqz3P660MFWt5tqx8TrH4Yy67GtQ/640?wx_fmt=other&amp;wxfrom=5&amp;wx_lazy=1&amp;wx_co=1&amp;tp=webp"></p><section data-tool="mdnice编辑器" data-website="https://www.mdnice.com"><h2 data-tool="mdnice编辑器"><span></span><span>简  介</span></h2><p data-tool="mdnice编辑器">在许多应用中，理解一个模型为什么会做出某种预测是至关重要的。然而，对于大型现代数据集，最好的准确性通常是通过复杂的模型来实现的，即使专家也很难解释，比如集成或深度学习模型。这造成了准确性和可解释性之间的紧张关系。作为回应，最近提出了各种方法来帮助用户解释复杂模型的预测。在这里，我们提出了一个统一的框架来解释预测，即SHAP (SHapley Additive exPlanations)，它为每个特征分配一个特定预测的重要性。SHAP框架的关键新组成部分是识别一类可加性特征重要性度量和理论结果，即该类中存在具有一组期望性质的唯一解。这个类统一了六个现有的方法，并且这个类中的几个最近的方法没有这些所需的属性。这意味着我们的框架可以为解释预测模型的新方法的发展提供信息。我们证明了基于SHAP框架提出的几种新方法比现有方法具有更好的计算性能和与人类直觉的更好一致性。</p></section><p><img data-imgfileid="100011036" data-ratio="0.40625" data-s="300,640" data-src="https://mmbiz.qpic.cn/mmbiz_png/5ia62S5YZaMwuj3lOHAiaHM4jrrFCy5BIw4RPq2JX2ZhubJAX9jzoH0GGfQB165WqZrzJGBrtGULU04E4uv4TNGw/640?wx_fmt=png&amp;from=appmsg" data-type="png" data-w="864" src="https://mmbiz.qpic.cn/mmbiz_png/5ia62S5YZaMwuj3lOHAiaHM4jrrFCy5BIw4RPq2JX2ZhubJAX9jzoH0GGfQB165WqZrzJGBrtGULU04E4uv4TNGw/640?wx_fmt=png&amp;from=appmsg"></p><section data-tool="mdnice编辑器" data-website="https://www.mdnice.com"><p data-tool="mdnice编辑器">SHapley加性解释（SHapley Additive explanation）的可视化，例如瀑布图、力图、各种类型的重要性图、依赖性图和相互作用图。这些图作用于由SHAP值矩阵和相应的特征数据集创建的“shapviz”对象。为方便起见，添加了R包的包装器‘xgboost’， ‘lightgbm’， ‘ fastshape ’， ‘shapr’， ‘h2o’， ‘treeshap’， ‘ dalx ’和‘kernel shape ’。通过分离可视化和计算，可以在图中显示因子变量，即使SHAP值是由需要数值特征的模型计算的。</p><h2 data-tool="mdnice编辑器"><span></span><span>软件包安装</span></h2><pre data-tool="mdnice编辑器"><span></span><code><span># From CRAN</span><br>install.packages(<span>"shapviz"</span>)<br><br><span># Or the newest version from GitHub:</span><br><span># install.packages("devtools")</span><br>devtools::install_github(<span>"ModelOriented/shapviz"</span>)<br></code></pre><pre data-tool="mdnice编辑器"><span></span><code><span>library</span>(shapviz)<br><span>library</span>(xgboost)<br><span>library</span>(caret)<br><span>library</span>(pROC)<br><span>library</span>(tibble)<br><span>library</span>(ROCit)<br></code></pre><h2 data-tool="mdnice编辑器"><span></span><span>数据读取</span></h2><h3 data-tool="mdnice编辑器"><span></span>原始数据<span></span></h3><pre data-tool="mdnice编辑器"><span></span><code>BreastCancer &lt;- read.csv(<span>"wisc_bc_data.csv"</span>, stringsAsFactors = <span>FALSE</span>)<br>str(BreastCancer)<br><span>## 'data.frame':	568 obs. of  32 variables:</span><br><span>##  $ id                     : int  842517 84300903 84348301 84358402 843786 844359 84458202 844981 84501001 845636 ...</span><br><span>##  $ diagnosis              : chr  "M" "M" "M" "M" ...</span><br><span>##  $ radius_mean            : num  20.6 19.7 11.4 20.3 12.4 ...</span><br><span>##  $ texture_mean           : num  17.8 21.2 20.4 14.3 15.7 ...</span><br><span>##  $ perimeter_mean         : num  132.9 130 77.6 135.1 82.6 ...</span><br><span>##  $ area_mean              : num  1326 1203 386 1297 477 ...</span><br><span>##  $ smoothness_mean        : num  0.0847 0.1096 0.1425 0.1003 0.1278 ...</span><br><span>##  $ compactne_mean         : num  0.0786 0.1599 0.2839 0.1328 0.17 ...</span><br><span>##  $ concavity_mean         : num  0.0869 0.1974 0.2414 0.198 0.1578 ...</span><br><span>##  $ concave_points_mean    : num  0.0702 0.1279 0.1052 0.1043 0.0809 ...</span><br><span>##  $ symmetry_mean          : num  0.181 0.207 0.26 0.181 0.209 ...</span><br><span>##  $ fractal_dimension_mean : num  0.0567 0.06 0.0974 0.0588 0.0761 ...</span><br><span>##  $ radius_se              : num  0.543 0.746 0.496 0.757 0.335 ...</span><br><span>##  $ texture_se             : num  0.734 0.787 1.156 0.781 0.89 ...</span><br><span>##  $ perimeter_se           : num  3.4 4.58 3.44 5.44 2.22 ...</span><br><span>##  $ area_se                : num  74.1 94 27.2 94.4 27.2 ...</span><br><span>##  $ smoothness_se          : num  0.00522 0.00615 0.00911 0.01149 0.00751 ...</span><br><span>##  $ compactne_se           : num  0.0131 0.0401 0.0746 0.0246 0.0335 ...</span><br><span>##  $ concavity_se           : num  0.0186 0.0383 0.0566 0.0569 0.0367 ...</span><br><span>##  $ concave_points_se      : num  0.0134 0.0206 0.0187 0.0188 0.0114 ...</span><br><span>##  $ symmetry_se            : num  0.0139 0.0225 0.0596 0.0176 0.0216 ...</span><br><span>##  $ fractal_dimension_se   : num  0.00353 0.00457 0.00921 0.00511 0.00508 ...</span><br><span>##  $ radius_worst           : num  25 23.6 14.9 22.5 15.5 ...</span><br><span>##  $ texture_worst          : num  23.4 25.5 26.5 16.7 23.8 ...</span><br><span>##  $ perimeter_worst        : num  158.8 152.5 98.9 152.2 103.4 ...</span><br><span>##  $ area_worst             : num  1956 1709 568 1575 742 ...</span><br><span>##  $ smoothness_worst       : num  0.124 0.144 0.21 0.137 0.179 ...</span><br><span>##  $ compactne_worst        : num  0.187 0.424 0.866 0.205 0.525 ...</span><br><span>##  $ concavity_worst        : num  0.242 0.45 0.687 0.4 0.535 ...</span><br><span>##  $ concave_points_worst   : num  0.186 0.243 0.258 0.163 0.174 ...</span><br><span>##  $ symmetry_worst         : num  0.275 0.361 0.664 0.236 0.399 ...</span><br><span>##  $ fractal_dimension_worst: num  0.089 0.0876 0.173 0.0768 0.1244 ...</span><br>dim(BreastCancer)<br><span>## [1] 568  32</span><br>table(BreastCancer$diagnosis)<br><span>## </span><br><span>##   B   M </span><br><span>## 357 211</span><br>data = na.omit(BreastCancer)<br>data = data[, -<span>1</span>]<br>data$diagnosis = factor(data$diagnosis)<br>sum(is.na(data))  <span># 检测数据是否有缺失</span><br><span>## [1] 0</span><br>data$diagnosis = ifelse(data$diagnosis == <span>"B"</span>, <span>0</span>, <span>1</span>)<br>table(data$diagnosis)<br><span>## </span><br><span>##   0   1 </span><br><span>## 357 211</span><br></code></pre><h3 data-tool="mdnice编辑器"><span></span>数据分割<span></span></h3><p data-tool="mdnice编辑器">将原始数据分割为训练集和测试集：</p><pre data-tool="mdnice编辑器"><span></span><code><span>library</span>(sampling)<br>set.seed(<span>123</span>)<br><span># 每层抽取70%的数据</span><br>train_id &lt;- strata(data, <span>"diagnosis"</span>, size = rev(round(table(data$diagnosis) * <span>0.7</span>)))$ID_unit<br><span># 训练数据</span><br>trainData &lt;- data[train_id, ]<br><span># 测试数据</span><br>testData &lt;- data[-train_id, ]<br></code></pre><h3 data-tool="mdnice编辑器"><span></span>构建输入数据格式<span></span></h3><pre data-tool="mdnice编辑器"><span></span><code>X_pred &lt;- data.matrix(trainData[, -<span>1</span>])<br>dtrain &lt;- xgboost::xgb.DMatrix(X_pred, label = trainData[, <span>1</span>], nthread = <span>1</span>)<br></code></pre><h2 data-tool="mdnice编辑器"><span></span><span>实例操作</span></h2><h3 data-tool="mdnice编辑器"><span></span>构建 xgboost 模型<span></span></h3><pre data-tool="mdnice编辑器"><span></span><code>fit &lt;- xgboost::xgb.train(data = dtrain, nrounds = <span>20</span>, nthread = <span>1</span>)<br>summary(fit)<br><span>##               Length Class              Mode       </span><br><span>## handle            1  xgb.Booster.handle externalptr</span><br><span>## raw           48522  -none-             raw        </span><br><span>## niter             1  -none-             numeric    </span><br><span>## call              4  -none-             call       </span><br><span>## params            2  -none-             list       </span><br><span>## callbacks         1  -none-             list       </span><br><span>## feature_names    30  -none-             character  </span><br><span>## nfeatures         1  -none-             numeric</span><br></code></pre><h3 data-tool="mdnice编辑器"><span></span>计算SHAP值<span></span></h3><pre data-tool="mdnice编辑器"><span></span><code>shapValue &lt;- shapviz(fit, X_pred = X_pred, X = trainData)<br></code></pre><pre data-tool="mdnice编辑器"><span></span><code>shapValue &lt;- shapviz(fit, X_pred = X_pred, X = trainData, interactions = <span>TRUE</span>)<br></code></pre><h2 data-tool="mdnice编辑器"><span></span>SHAP可视化</h2><h3 data-tool="mdnice编辑器"><span></span>sv_importance()<span></span></h3><p data-tool="mdnice编辑器">参数说明：kind = c("bar", "beeswarm", "both", "no") 表示绘图样式。</p><h4 data-tool="mdnice编辑器"><span></span>柱状图<span></span></h4><p data-tool="mdnice编辑器">经典柱状图。</p><pre data-tool="mdnice编辑器"><span></span><code>sv_importance(shapValue, kind = <span>"bar"</span>) + theme_bw()<br></code></pre><p><img data-galleryid="" data-imgfileid="100011037" data-ratio="0.707395498392283" data-s="300,640" data-src="https://mmbiz.qpic.cn/mmbiz_png/5ia62S5YZaMwuj3lOHAiaHM4jrrFCy5BIwJv8P8icmwJFLWVlXwE2VI6EB0oMTuBS4BRKxSrGu1GwkOGs11BbyqpQ/640?wx_fmt=png&amp;from=appmsg" data-type="png" data-w="622" src="https://mmbiz.qpic.cn/mmbiz_png/5ia62S5YZaMwuj3lOHAiaHM4jrrFCy5BIwJv8P8icmwJFLWVlXwE2VI6EB0oMTuBS4BRKxSrGu1GwkOGs11BbyqpQ/640?wx_fmt=png&amp;from=appmsg"></p><h4 data-tool="mdnice编辑器"><span></span>蜂群图<span></span></h4><p data-tool="mdnice编辑器">计算每个样本每个特征的SHAP值，可以直观地从全局理解模型。每一行代表一个特征，横坐标为SHAP值。一个点代表一个样本，颜色表示特征值（黄色高，紫色低）。图中可以看出"concave_points_mean","area_worst", "concave_points_worst", "texture_worst","area_se" 特征最重要。</p><pre data-tool="mdnice编辑器"><span></span><code>sv_importance(shapValue, kind = <span>"beeswarm"</span>) + theme_bw()<br></code></pre><p><img data-galleryid="" data-imgfileid="100011038" data-ratio="0.7291666666666666" data-s="300,640" data-src="https://mmbiz.qpic.cn/mmbiz_png/5ia62S5YZaMwuj3lOHAiaHM4jrrFCy5BIwmWwFfQGYNjdxWDZsacZ7EpGSba3eZvgWjuRpoZODSs6K69ib3OC6Gog/640?wx_fmt=png&amp;from=appmsg" data-type="png" data-w="672" src="https://mmbiz.qpic.cn/mmbiz_png/5ia62S5YZaMwuj3lOHAiaHM4jrrFCy5BIwmWwFfQGYNjdxWDZsacZ7EpGSba3eZvgWjuRpoZODSs6K69ib3OC6Gog/640?wx_fmt=png&amp;from=appmsg"></p><h4 data-tool="mdnice编辑器"><span></span>两种图形叠加<span></span></h4><pre data-tool="mdnice编辑器"><span></span><code>sv_importance(shapValue, kind = <span>"both"</span>) + theme_bw()<br></code></pre><p><img data-galleryid="" data-imgfileid="100011039" data-ratio="0.7227138643067846" data-s="300,640" data-src="https://mmbiz.qpic.cn/mmbiz_png/5ia62S5YZaMwuj3lOHAiaHM4jrrFCy5BIwWhtGqyvgG65ZzHHxDhMKwwibkib0XZRLojSQ7CVTDQriaZzshJrRathxQ/640?wx_fmt=png&amp;from=appmsg" data-type="png" data-w="678" src="https://mmbiz.qpic.cn/mmbiz_png/5ia62S5YZaMwuj3lOHAiaHM4jrrFCy5BIwWhtGqyvgG65ZzHHxDhMKwwibkib0XZRLojSQ7CVTDQriaZzshJrRathxQ/640?wx_fmt=png&amp;from=appmsg"></p><h3 data-tool="mdnice编辑器"><span></span>提出重要的特征变量：<span></span></h3><pre data-tool="mdnice编辑器"><span></span><code>shapValue$baseline<br><span>## [1] 0.3718869</span><br>impor &lt;- sort(colMeans(abs(shapValue$S)), decreasing = <span>T</span>)[<span>1</span>:<span>6</span>]<br>names(impor)<br><span>## [1] "concave_points_mean"  "area_worst"           "concave_points_worst"</span><br><span>## [4] "texture_worst"        "area_se"              "perimeter_worst"</span><br></code></pre><h3 data-tool="mdnice编辑器"><span></span>sv_dependence()<span></span></h3><h4 data-tool="mdnice编辑器"><span></span>依赖图<span></span></h4><p data-tool="mdnice编辑器">依赖性图用于研究特征效应和交互作用。依赖图展示的是一个或两个特征对机器学习模型的预测结果的边际效应，可以显示目标和特征之间的关系。展示的是一个特征的值与该特征的SHAP值。依赖图的一个重要假设是第一个特征与第二个特征不相关。有时候特征间存在交互效应，这个时候可以通过加入第二个特征来显示，这里是点的颜色。</p><pre data-tool="mdnice编辑器"><span></span><code>sv_dependence(shapValue,v=names(impor))<br></code></pre><p><img data-galleryid="" data-imgfileid="100011040" data-ratio="0.45092592592592595" data-s="300,640" data-src="https://mmbiz.qpic.cn/mmbiz_png/5ia62S5YZaMwuj3lOHAiaHM4jrrFCy5BIwfFuXVD18HSSpHfmVSkofC8xzpQ8ibtnP8Z6rTfH2k3g8icErkVqLO9OQ/640?wx_fmt=png&amp;from=appmsg" data-type="png" data-w="1080" src="https://mmbiz.qpic.cn/mmbiz_png/5ia62S5YZaMwuj3lOHAiaHM4jrrFCy5BIwfFuXVD18HSSpHfmVSkofC8xzpQ8ibtnP8Z6rTfH2k3g8icErkVqLO9OQ/640?wx_fmt=png&amp;from=appmsg"></p><pre data-tool="mdnice编辑器"><span></span><code>sv_dependence(shapValue, v = <span>"concave_points_mean"</span>, color_var = <span>NULL</span>)<br></code></pre><p><img data-galleryid="" data-imgfileid="100011041" data-ratio="0.706821480406386" data-s="300,640" data-src="https://mmbiz.qpic.cn/mmbiz_png/5ia62S5YZaMwuj3lOHAiaHM4jrrFCy5BIwkHH2Nm9EDD5m6cMwlNIEQrcuAk3BTwpto6EQJa9bIdVjmykjPf4lAw/640?wx_fmt=png&amp;from=appmsg" data-type="png" data-w="689" src="https://mmbiz.qpic.cn/mmbiz_png/5ia62S5YZaMwuj3lOHAiaHM4jrrFCy5BIwkHH2Nm9EDD5m6cMwlNIEQrcuAk3BTwpto6EQJa9bIdVjmykjPf4lAw/640?wx_fmt=png&amp;from=appmsg"></p><p data-tool="mdnice编辑器">SHAP dependence plots展示特征值大小与SHAP值之间的关系，该图清楚地展示了单个特征是如何影响模型的预测结果的。</p><h3 data-tool="mdnice编辑器"><span></span>sv_waterfall()<span></span></h3><h4 data-tool="mdnice编辑器"><span></span>瀑布图<span></span></h4><p data-tool="mdnice编辑器">用水力瀑布图研究单个或平均预测。</p><p data-tool="mdnice编辑器">模型估计的值0.987，样本2的预测值为0.372。对模型预测贡献较大的变量为"concave_points_mean","area_worst", "concave_points_worst", "texture_worst","area_se", "perimeter_worst"。</p><pre data-tool="mdnice编辑器"><span></span><code>sv_waterfall(shapValue, row_id = <span>2</span>, max_display = <span>15</span>)<br></code></pre><p><img data-galleryid="" data-imgfileid="100011042" data-ratio="0.6769005847953217" data-s="300,640" data-src="https://mmbiz.qpic.cn/mmbiz_png/5ia62S5YZaMwuj3lOHAiaHM4jrrFCy5BIw91iaAXB3VibXZZMiaU5t2icLPRKBNPJCSp546JaC6M6N9ExnfCQTzohyYw/640?wx_fmt=png&amp;from=appmsg" data-type="png" data-w="684" src="https://mmbiz.qpic.cn/mmbiz_png/5ia62S5YZaMwuj3lOHAiaHM4jrrFCy5BIw91iaAXB3VibXZZMiaU5t2icLPRKBNPJCSp546JaC6M6N9ExnfCQTzohyYw/640?wx_fmt=png&amp;from=appmsg"></p><h3 data-tool="mdnice编辑器"><span></span>sv_force()<span></span></h3><p data-tool="mdnice编辑器">单个样本力图既force plot图是waterfall plot 图的另外一种展示形式，本质上是一样的。</p><pre data-tool="mdnice编辑器"><span></span><code>sv_force(shapValue, row_id = <span>2</span>, max_display = <span>6</span>)<br></code></pre><p><img data-galleryid="" data-imgfileid="100011043" data-ratio="0.35198821796759944" data-s="300,640" data-src="https://mmbiz.qpic.cn/mmbiz_png/5ia62S5YZaMwuj3lOHAiaHM4jrrFCy5BIwpOy8WKfLDqicR4QOicjVOnIjj9kdNehLIM83VXycur1NysLN1SGGc2MQ/640?wx_fmt=png&amp;from=appmsg" data-type="png" data-w="679" src="https://mmbiz.qpic.cn/mmbiz_png/5ia62S5YZaMwuj3lOHAiaHM4jrrFCy5BIwpOy8WKfLDqicR4QOicjVOnIjj9kdNehLIM83VXycur1NysLN1SGGc2MQ/640?wx_fmt=png&amp;from=appmsg"></p><h3 data-tool="mdnice编辑器"><span></span>sv_interaction()<span></span></h3><p data-tool="mdnice编辑器">互作图是水瀑图的替代方案。interaction value 是 SHAP 值更高阶的一种玩法，完美展示交互效应。</p><pre data-tool="mdnice编辑器"><span></span><code>sv_interaction(shapValue, kind = <span>"beeswarm"</span>, max_display = <span>6</span>)<br></code></pre><p><img data-galleryid="" data-imgfileid="100011044" data-ratio="0.46944444444444444" data-s="300,640" data-src="https://mmbiz.qpic.cn/mmbiz_png/5ia62S5YZaMwuj3lOHAiaHM4jrrFCy5BIwZiboxVC6Q1tW44oAicOnpLBVRz1NdwyNzAPGWrGrebLPZWuWUT7ib4nicw/640?wx_fmt=png&amp;from=appmsg" data-type="png" data-w="1080" src="https://mmbiz.qpic.cn/mmbiz_png/5ia62S5YZaMwuj3lOHAiaHM4jrrFCy5BIwZiboxVC6Q1tW44oAicOnpLBVRz1NdwyNzAPGWrGrebLPZWuWUT7ib4nicw/640?wx_fmt=png&amp;from=appmsg"></p><h2 data-tool="mdnice编辑器"><span></span><span>结果解读</span></h2><p data-tool="mdnice编辑器">通过xgboost建模筛选变量，并计算每个变量的SHAP值，对重要变量进行排序筛选，得到6个较为重要的变量。</p><h4 data-tool="mdnice编辑器"><span></span><span>Reference</span><span></span></h4><p data-tool="mdnice编辑器">Scott M. Lundberg and Su-In Lee. A Unified Approach to Interpreting Model Predictions. Advances in Neural Information Processing Systems 30 (2017).</p></section><section><mp-common-videosnap data-pluginname="mpvideosnap" data-url="https://findermp.video.qq.com/251/20304/stodownload?encfilekey=rjD5jyTuFrIpZ2ibE8T7YmwgiahniaXswqzQrBeHXxYt5Mf7QuWLAqJSGjZlKV8gk5zc8csDUnu4ERQJQrnWCznlPYk6IE4uPRG3Epb60wIpYbxTgGfYZA0BA&amp;token=cztXnd9GyrFrCDZ0Kn1zlNLF977HwzLaibciafx1UzJuldFicicqd2vWGUH7Fyk3eWWRibtyAI78Jicgnz7t6hicGI14ZSyiczp9MZ9ocLcbHiaHp39XMDlZxR2tAQ15cId7Um8dp&amp;idx=1&amp;dotrans=0&amp;hy=SH&amp;m=&amp;scene=2&amp;uzid=2" data-headimgurl="http://wx.qlogo.cn/finderhead/Q3auHgzwzM6NFe6qfZ98pccnStLOBzJIic5564gE1oW2m34RtSicQHIQ/0" data-username="v2_060000231003b20faec8c6eb891cc2ddca0ce43cb07767727967ddf958ff98912bf15d898b0d@finder" data-nickname="桓峰基因" data-desc="ML 46. 机器学习之利用SHAP解释模型特征变量的重要性#机器学习#临床预测#生信分析@桓峰基因" data-nonceid="15279076502436302088" data-type="video" data-mediatype="undefined" data-authiconurl="" data-from="new" data-width="1920" data-height="1080" data-id="export/UzFfAgtgekIEAQAAAAAAuxMU5wzrFQAAAAstQy6ubaLX4KHWvLEZgBPE_KJgBmAfENWKzNPgMIshawBnMHwBK2FuRwJ1eRCm" data-isdisabled="0" data-errortips=""></mp-common-videosnap></section><section data-tool="mdnice编辑器" data-website="https://www.mdnice.com"><section data-tool="mdnice编辑器" data-website="https://www.mdnice.com"><section data-tool="mdnice编辑器" data-website="https://www.mdnice.com"><p><span>桓峰基因，铸造成功的您！</span></p><p><span>未来桓峰基因公众号将不间断的推出机器学习系列生信分析教程，</span></p><p><span>敬请期待！！</span></p></section><p><span>桓峰基因官网正式上线，请大家多多关注，还有很多不足之处，大家多多指正！</span><span>http://www.kyohogene.com/</span></p><p><span>桓峰基因和投必得合作，文章润色优惠85折，需要文章润色的老师可以直接到网站输入领取桓峰基因专属优惠券码：KYOHOGENE，然后上传，付款时选择桓峰基因优惠券即可享受85折优惠哦！https://www.topeditsci.com/</span></p><p><span><img data-galleryid="" data-imgfileid="100011045" data-ratio="0.5657407407407408" data-s="300,640" data-src="https://mmbiz.qpic.cn/mmbiz_png/5ia62S5YZaMwDj3ich1uOSggdibWHw5pgkMx26IaaiaQoKJbU2EaQI2CYh9n2stiaMicbs1RyInFfqO6qWwpDxsFfl8w/640?wx_fmt=other&amp;wxfrom=5&amp;wx_lazy=1&amp;wx_co=1&amp;tp=webp" data-type="png" data-w="1080" src="https://mmbiz.qpic.cn/mmbiz_png/5ia62S5YZaMwDj3ich1uOSggdibWHw5pgkMx26IaaiaQoKJbU2EaQI2CYh9n2stiaMicbs1RyInFfqO6qWwpDxsFfl8w/640?wx_fmt=other&amp;wxfrom=5&amp;wx_lazy=1&amp;wx_co=1&amp;tp=webp"></span></p></section></section><p><mp-style-type data-value="3"></mp-style-type></p></div>  
<hr>
<a href="https://mp.weixin.qq.com/s/YDxbHmDea6hXDjs-l1e6mA",target="_blank" rel="noopener noreferrer">原文链接</a>
